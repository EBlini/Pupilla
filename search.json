[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/articles/Pupilla.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Pupilla","text":"package currently available GitHub. installation requires R package remotes.","code":"# install.packages(\"remotes\") remotes::install_github(\"EBlini/Pupilla\")"},{"path":"/articles/Pupilla.html","id":"scope","dir":"Articles","previous_headings":"","what":"Scope","title":"Pupilla","text":"collection functions wrappers useful preprocessing analysis eyetracking data, special focus pupillometry. Functions generally hardware-agnostic, designed data collected third-part experiment builders OpenSesame. Functions tested Windows machines. functions considered development: requests suggestions welcome, :) . Manuals, references, vignettes available link: https://eblini.github.io/Pupilla/ useful references, example results functions, see Blini Zorzi, 2023 Blini, Arrighi, Anobile, 2024.","code":""},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Pupilla::Advanced_statistical_analyses","text":"Pupilla gathers several functions designed facilitate analysis pupillometry experiments commonly performed cognitive neuroscience, e.g. event-related designs, although use much general. vignette cover statistical modelling step. Pupilla provides functions implement two approaches: Crossvalidated LMEMs Mathôt & Vilotijević, 2022. original - thus yet fully validated scientific articles - approach feature reduction. use data Zhou et al., 2022 better comparison - indeed differences implementation LMEMs R Python, top course specific choices ’ve made within package. grateful authors sharing data allowing us reproducible, exploitable science.","code":""},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"prepping-the-data","dir":"Articles","previous_headings":"","what":"Prepping the data","title":"Pupilla::Advanced_statistical_analyses","text":"need following R packages: python interface: Note package reticulate requires python environment installation required modules. package needed read .pkl files directly within R, original format data. Accordingly, following chunk run python engine - , need include within reticulate repl using markdown. use read original data, convert pandas dataframe, move R environment. python environment available R py. can thus manipulate data usual functions. particular, variable pupil read array, whereas prefer long dataframe R. thus reshape bit data follows - based understanding structure: add explicit “Trial” variable data. variable “Set_Size” also converted factor. NA data. generally problematic LMEMs, can handle well slightly unbalanced designs, values well omitted. slightly problematic second approach, features reduction, missing values may lead loss entire trial. approach, sort interpolation warranted , course, gaps large. vignette simply interpolate missing values linearly zoo::na.approx(). Note function work NAs located beginning end vector, won’t get rid NAs. plot average pupil size Set_Size Color_type. plot looks quite like original one, sould far original data.  really depicting variability. However, matters : 1) large effect Set_Size; 2) may (well, know paper , :) ) interaction Set_Size Color_type effect non-prototypical color reversed 1 4. Let’s analyze data!","code":"library(\"dplyr\") ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(\"Pupilla\") library(\"ggplot2\") library(\"emmeans\") library(\"lmerTest\") ## Loading required package: lme4 ## Loading required package: Matrix ##  ## Attaching package: 'lmerTest' ## The following object is masked from 'package:lme4': ##  ##     lmer ## The following object is masked from 'package:stats': ##  ##     step library(\"zoo\") ##  ## Attaching package: 'zoo' ## The following objects are masked from 'package:base': ##  ##     as.Date, as.Date.numeric options(dplyr.summarise.inform = FALSE) library(\"reticulate\")  # #create python environment #conda_create(\"my_env\") #use_miniconda(\"my_env\")  # #install packages in the environment # py_install(\"pandas\") # py_install(\"datamatrix\") from datamatrix import io, convert  address= \"data\\\\zhou_et_al_2021.pkl\"  data= io.readpickle(address)  data= convert.to_pandas(data)  quit DF= py$data #bring to R  DF2 = lapply(1:nrow(DF), function(x) {   res = data.frame(     Pupil = as.vector(DF$pupil[[x]]),     Set_size = DF$set_size[x],     Subject = DF$subject_nr[x],     Color_type = DF$color_type[x],     Time = seq(0, 3, length = 300)   )      return(res)    })  DF2= do.call(rbind, DF2) DF2= DF2 %>%    group_by(Subject, Time) %>%    mutate(Trial= 1:n())  DF2= data.frame(DF2)  DF2$Set_size= as.factor(DF2$Set_size) sum(is.na(DF2$Pupil)) ## [1] 35786 DF2= DF2 %>%    group_by(Subject, Trial) %>%    mutate(Pupil= zoo::na.approx(Pupil, na.rm = F))  sum(is.na(DF2$Pupil)) ## [1] 2009 DF2 %>%    group_by(Subject, Time, Color_type, Set_size) %>%    summarise(Pupil= mean(Pupil, na.rm= T)) %>%   group_by(Time, Color_type, Set_size) %>%    summarise(Pupil= mean(Pupil)) %>%   mutate(Set_size= as.factor(Set_size)) %>%    ggplot(aes(y= Pupil, x= Time,               color= Set_size,               linetype= Color_type,              group = interaction(Set_size, Color_type))) +   geom_line(linewidth= 1.2) +   theme(text= element_text(size= 16,                            face=\"bold\")) +   xlab(\"Time (s)\") +   ylab(\"Pupil size (a.u.)\") +   ggtitle(\"Data from: Zhou, Lorist, and Mathôt (2022)\")"},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"crossvalidated-lmems","dir":"Articles","previous_headings":"","what":"Crossvalidated LMEMs","title":"Pupilla::Advanced_statistical_analyses","text":"approach Mathôt & Vilotijević, 2022, trials participant assigned deterministically one N folds. N-1 folds circularly used training set; , LMEMs performed timepoint, timepoint peak t-value (fixed effect interaction) used test set confirm overall consistency target effect across folds. approach computationally efficient powerful suggesting presence consistent experimental effect somewhere along time course trials. Pupilla. ’s ! first take look global effects, LMEMs tested relative peaks: First, may notice results taken lmerTest::lmer() reflect default contrast settings R, treatment coding. words, case factors first level taken reference. case ’s pretty clear us aim compare Set_size 1 vs 4; want compare explicity contrasts, refactor variables. understanding packages may perform “omnibus tests”; R feasible, e.g. car::Anova(), perhaps implemented feature. interpretation , however, omnibus test (e.g., main effect ANOVA), specific comparisons. also notice main inferential statistic t value, rather z F value. said, results positive Set_size (differs 1) interaction Color_type Set_size 1 4. therefore taken evidence presence effect somewhere along time course trials. following table reports statistics fold, fold left . useful understand peaks located. First, comparisons Set_size 1 vs 2 3 similar locating peaks around 1 second. Results slightly sparse 1 vs 4 comparison (1 2.8 s). find main effect Color_type . due contrasts used, differences trials assigned folds, presence possible convergence failures, etc. see, example, t values main effect Color_type positive two folds, negative one. due, , funny convergence, simply fact overfitting occurrred one specific time point (sample 5). introduce notion consensus across folds. Finally, interaction also seemingly consistent 1.4 1.7 seconds. Overall, seems good agreement original findings, notwithstanding differences implementation. , however, couple caveats, also mentioned authors. First, temporal information provided approach rather coarse. can test presence effect somewhere along course trial, though specific timepoints may rather vague. Second, presence two distinct loci effects, approach entirely appropriate, especially direction effects opposite direction. Finally, tested time point chosen one peak statistic (e.g., t value), approach may prone overfitting; time points may , fact, representative effects hand.","code":"#the data data= DF2 #lme4::lmer-style formula  #here we use only random intercepts formula= \"Pupil ~ Set_size*Color_type + (1|Subject)\" #you also have to supply explicitly the names of the variables dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" #how many folds? nfolds= 3 #used for the consensus across folds - see below t_thresh= 1.9 consensus_thresh = 0.99  cv= decode_signal(data= data,                    formula= formula,                   dv= dv,                   time= time,                   id= id,                   trial= trial,                   nfolds= nfolds,                   t_thresh= t_thresh,                   consensus_thresh= consensus_thresh) ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') cv$Peaks_test ##                      Effect      Test_t    Test_df       Test_p ## 1               (Intercept) -12.0345532   31.90004 2.127767e-13 ## 2                 Set_size2   7.4219908 7276.01675 1.284641e-13 ## 3                 Set_size3  14.4253720 7276.01727 1.564918e-46 ## 4                 Set_size4  12.6268559 7263.07280 3.595688e-36 ## 5           Color_typeproto  -1.5116082 7269.07742 1.306770e-01 ## 6 Set_size2:Color_typeproto   0.8674076 7270.09839 3.857473e-01 ## 7 Set_size3:Color_typeproto   1.0893240 7273.07358 2.760471e-01 ## 8 Set_size4:Color_typeproto   2.4009727 7273.04856 1.637651e-02 cv$All_Folds ##    Fold                    Effect     Peak_t Peak_obs  Peak_time ## 1     1               (Intercept) -12.141355       89 0.88294314 ## 2     2               (Intercept) -11.509067       87 0.86287625 ## 3     3               (Intercept) -12.037152       89 0.88294314 ## 4     1                 Set_size2   6.233502       95 0.94314381 ## 5     2                 Set_size2   5.663626       89 0.88294314 ## 6     3                 Set_size2   7.076464       97 0.96321070 ## 7     1                 Set_size3  12.371973       98 0.97324415 ## 8     2                 Set_size3  11.366762       98 0.97324415 ## 9     3                 Set_size3  11.770977       97 0.96321070 ## 10    1                 Set_size4  13.232442      103 1.02341137 ## 11    2                 Set_size4  12.609223      282 2.81939799 ## 12    3                 Set_size4  13.366514      221 2.20735786 ## 13    1           Color_typeproto  -2.484261      167 1.66555184 ## 14    2           Color_typeproto  -2.121288      159 1.58528428 ## 15    3           Color_typeproto   1.807755        5 0.04013378 ## 16    1 Set_size2:Color_typeproto   2.398834      165 1.64548495 ## 17    2 Set_size2:Color_typeproto   2.987624      156 1.55518395 ## 18    3 Set_size2:Color_typeproto  -1.623268        7 0.06020067 ## 19    1 Set_size3:Color_typeproto   1.707470      158 1.57525084 ## 20    2 Set_size3:Color_typeproto   2.071359      146 1.45484950 ## 21    3 Set_size3:Color_typeproto  -2.007344        8 0.07023411 ## 22    1 Set_size4:Color_typeproto   3.216884      171 1.70568562 ## 23    2 Set_size4:Color_typeproto   2.794211      159 1.58528428 ## 24    3 Set_size4:Color_typeproto   1.950378      142 1.41471572"},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"consensus","dir":"Articles","previous_headings":"Crossvalidated LMEMs","what":"Consensus","title":"Pupilla::Advanced_statistical_analyses","text":"common problem, machine learning, find consensus hyperparameters obtained different folds. Particularly need build one final model interpret results (see, e.g., package FCnet analysis neuroimaging data elastic nets). Long story short, one possible solution put forward Pupilla quite simple, though arbitrary: simply keep track timepoints associated given threshold, e.g. t statistic 1.9 case, consider agreement across folds … time points show consistently across folds! ’s simple . specific example ask folds agreement (>99%), meaning timepoints must remain significant regardless fold left data. (ensure none folds particular leverage driving overal results). effects specified, consensus across folds? Yes! consensus clear contrast within Set_size interaction Color_type (1 vs 4), latter case sample 136 147. can formally test consensus window another LMEM: , , presence effect confirmed. summarise, approach advantage returning precise time window given experimental effect; maintains computational efficiency crossvalidated approach; capable highlight potentially clusters contiguous. downside arbitrary choices - e.g., threshold statistic - must specified beforehand. personal take matter , researchers, start comfortable degrees freedom, unavoidable job, embrace , just resolve tranparently report choices avoid overselling stuff. get , really ingrained . Keep mind , however, conflict can resolved elegantly preregistration experimental methods. rate, long discussion vignette. Let’s introduce second approach pursued Pupilla: features reduction.","code":"cv$Consensus ## $`(Intercept)` ##   [1]  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 ##  ## $Set_size2 ##   [1]  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 178 ##  ## $Set_size3 ##   [1]  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 ## [249] 295 296 297 298 299 300 ##  ## $Set_size4 ##   [1]  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 ## [249] 297 298 299 300 ##  ## $Color_typeproto ## numeric(0) ##  ## $`Set_size2:Color_typeproto` ## numeric(0) ##  ## $`Set_size3:Color_typeproto` ## numeric(0) ##  ## $`Set_size4:Color_typeproto` ##  [1] 136 138 139 141 142 143 144 145 146 147 cv$Consensus_test ##                      Effect    Test_t    Test_df       Test_p ## 1               (Intercept) -2.447735   44.98978 0.0183421194 ## 2                 Set_size2  3.543109 7276.01207 0.0003979187 ## 3                 Set_size3  3.052632 7276.01359 0.0022766268 ## 4                 Set_size4  2.915928 7276.01471 0.0035571531 ## 5           Color_typeproto        NA         NA           NA ## 6 Set_size2:Color_typeproto        NA         NA           NA ## 7 Set_size3:Color_typeproto        NA         NA           NA ## 8 Set_size4:Color_typeproto  2.685758 7274.04215 0.0072529680"},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"feature-reduction","dir":"Articles","previous_headings":"","what":"Feature reduction","title":"Pupilla::Advanced_statistical_analyses","text":"live time big data. result, often necessary (empowering) reduce dimensions initial data , much manageable features preserve original variability. example Principal components analysis Independent Components Analysis rich data (e.g., neuroimaging) can reduced features, can enter multivariate analyses (see, e.g., FCnet). can done pupillometry data. fact, pupil dilation strongly autocorrelated time, approach potentially effective. Pupilla::reduce_PCA() Pupilla::reduce_ICA() attempt summarising trial scores; scores reflect contribution pupil diameter time point, weighted loadings matrix. loadings vary function importance contribution time point, thus capturing sort relevant pattern data. notation Pupilla similar used : used PCA (though ICA similar specific case). can see approach tremendously effective reducing data, 2 components can explain 90% original data! means can summarise trial describe fairly well pattern pupil dilation 2 values! Generally speaking first component captures main axis variability, ends describing best overall shape curves seen original plot . can depict :  loadings suggest first PC captures overall dilation/constriction occurring late stages trial, 1 second. (Keep mind sign loadings completely arbitrary, plot well reversed, know data probably refers dilation.) , following components gruadually capture remaining variability, e.g.:  Meaning go , likely capture idiosincratic (small) trial-wise changes. really case second component (24% variance explained), captures well likely initial response, e.g. pupillary light reflex. note interpretation: PCA descriptive model, imply underlying, originating process. interpretation part completely experimenter. case, however, inferential technique. uses, shape loadings plot likely highlight segregated, least partially independent processes. move forward assessing, thus, obtained scores. Scores can , course, summarised per subject perform classic ANOVAs, used within LMEMs. choose second approach now, though still summarise data depiction purposes.","code":"#the data data= DF2 #variables names should be supplied explicitly  dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" #append to the reduced dataframe add= c(\"Set_size\", \"Color_type\")  rf = reduce_PCA(   data = data,   dv = dv,   time = time,   id = id,   trial = trial,   add = add ) ## Warning in reduce_PCA(data = data, dv = dv, time = time, id = id, trial = trial, : NAs in the data will be discarded: ##             check the data! rf$summaryPCA[,1:4] ##                               PC1        PC2       PC3       PC4 ## Standard deviation     3229.38700 1941.74683 722.69764 489.68396 ## Proportion of Variance    0.67641    0.24454   0.03388   0.01555 ## Cumulative Proportion     0.67641    0.92096   0.95483   0.97039 plot_loadings(\"PC1\", rf) plot_loadings(\"PC2\", rf) #summarise scores Scores= rf$Scores %>%    group_by(id, Set_size, Color_type) %>%    summarise(PC1= mean(PC1),             PC2= mean(PC2)) Scores$Set_size= as.factor(Scores$Set_size) rf$Scores$Set_size= as.factor(rf$Scores$Set_size)"},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"pc1","dir":"Articles","previous_headings":"Feature reduction","what":"PC1","title":"Pupilla::Advanced_statistical_analyses","text":"can fit LMEM model first PC: see, , large effect Set_size, interaction Color_type occurring 1 vs 4 contrast. package emmeans can avoid refactoring compute contrasts: , indeed, significant contrast. can see inversion effect prototypical / non-prototypical color two set sizes.","code":"mod_pc1= lmer(PC1 ~ Color_type*Set_size + (1|id),               rf$Scores) #note that we used the original dataframe summary(mod_pc1) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest'] ## Formula: PC1 ~ Color_type * Set_size + (1 | id) ##    Data: rf$Scores ##  ## REML criterion at convergence: 134493.4 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -4.9087 -0.6031  0.0047  0.6025  5.8052  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  id       (Intercept) 1662005  1289     ##  Residual             7524608  2743     ## Number of obs: 7202, groups:  id, 30 ##  ## Fixed effects: ##                           Estimate Std. Error       df t value Pr(>|t|)     ## (Intercept)               -1813.69     252.48    36.97  -7.184 1.62e-08 *** ## Color_typeproto            -179.27     129.73  7165.06  -1.382   0.1670     ## Set_size2                   608.64     129.25  7165.04   4.709 2.54e-06 *** ## Set_size3                  1564.30     128.97  7165.05  12.129  < 2e-16 *** ## Set_size4                  2146.06     129.19  7165.08  16.612  < 2e-16 *** ## Color_typeproto:Set_size2   241.04     183.28  7165.05   1.315   0.1885     ## Color_typeproto:Set_size3   119.03     182.78  7165.06   0.651   0.5149     ## Color_typeproto:Set_size4   398.82     183.16  7165.08   2.177   0.0295 *   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) Clr_ty St_sz2 St_sz3 St_sz4 C_:S_2 C_:S_3 ## Colr_typprt -0.255                                           ## Set_size2   -0.256  0.498                                    ## Set_size3   -0.256  0.499  0.501                             ## Set_size4   -0.256  0.498  0.500  0.501                      ## Clr_typ:S_2  0.180 -0.708 -0.705 -0.353 -0.352               ## Clr_typ:S_3  0.181 -0.710 -0.353 -0.706 -0.353  0.502        ## Clr_typ:S_4  0.180 -0.708 -0.352 -0.353 -0.705  0.501  0.503 emm_options(lmer.df = \"asymptotic\") mm= emmeans(mod_pc1, ~ Color_type:Set_size) mm ##  Color_type Set_size emmean  SE  df asymp.LCL asymp.UCL ##  nonproto   1         -1814 252 Inf     -2309     -1319 ##  proto      1         -1993 253 Inf     -2488     -1498 ##  nonproto   2         -1205 253 Inf     -1700      -710 ##  proto      2         -1143 253 Inf     -1638      -648 ##  nonproto   3          -249 252 Inf      -744       245 ##  proto      3          -310 252 Inf      -804       185 ##  nonproto   4           332 252 Inf      -162       827 ##  proto      4           552 253 Inf        57      1047 ##  ## Degrees-of-freedom method: asymptotic  ## Confidence level used: 0.95 contrast(mm, method = \"pairwise\", interaction = T) ##  Color_type_pairwise Set_size_pairwise estimate  SE  df z.ratio p.value ##  nonproto - proto    1 - 2                  241 183 Inf   1.315  0.1885 ##  nonproto - proto    1 - 3                  119 183 Inf   0.651  0.5149 ##  nonproto - proto    1 - 4                  399 183 Inf   2.177  0.0295 ##  nonproto - proto    2 - 3                 -122 183 Inf  -0.668  0.5040 ##  nonproto - proto    2 - 4                  158 183 Inf   0.862  0.3885 ##  nonproto - proto    3 - 4                  280 182 Inf   1.533  0.1252 ##  ## Degrees-of-freedom method: asymptotic ggplot(Scores, aes(y= PC1, x= Set_size, fill= Color_type)) +   geom_boxplot() +   theme(text= element_text(size= 16,                            face=\"bold\"))"},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"pc2","dir":"Articles","previous_headings":"Feature reduction","what":"PC2","title":"Pupilla::Advanced_statistical_analyses","text":"PC2, hand: find effect, reiterating interaction probably appears later course trial.","code":"mod_pc2= lmer(PC2 ~ Color_type*Set_size + (1|id),                rf$Scores) summary(mod_pc2) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest'] ## Formula: PC2 ~ Color_type * Set_size + (1 | id) ##    Data: rf$Scores ##  ## REML criterion at convergence: 121258.8 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -5.0713 -0.5643 -0.0062  0.5856  5.9442  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  id       (Intercept)  473867   688.4   ##  Residual             1192655  1092.1   ## Number of obs: 7202, groups:  id, 30 ##  ## Fixed effects: ##                           Estimate Std. Error      df t value Pr(>|t|)     ## (Intercept)                1407.13     130.84   33.35  10.755 2.22e-12 *** ## Color_typeproto             -79.48      51.65 7165.03  -1.539  0.12388     ## Set_size2                  -135.53      51.46 7165.02  -2.634  0.00846 **  ## Set_size3                    58.57      51.35 7165.03   1.141  0.25401     ## Set_size4                   372.42      51.43 7165.05   7.241 4.92e-13 *** ## Color_typeproto:Set_size2   -24.67      72.97 7165.03  -0.338  0.73534     ## Color_typeproto:Set_size3    37.29      72.77 7165.04   0.512  0.60836     ## Color_typeproto:Set_size4    25.15      72.92 7165.05   0.345  0.73014     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) Clr_ty St_sz2 St_sz3 St_sz4 C_:S_2 C_:S_3 ## Colr_typprt -0.196                                           ## Set_size2   -0.196  0.498                                    ## Set_size3   -0.197  0.499  0.501                             ## Set_size4   -0.197  0.498  0.500  0.501                      ## Clr_typ:S_2  0.139 -0.708 -0.705 -0.353 -0.352               ## Clr_typ:S_3  0.139 -0.710 -0.353 -0.706 -0.353  0.502        ## Clr_typ:S_4  0.139 -0.708 -0.352 -0.353 -0.705  0.501  0.503"},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"rotated-principal-components-analysis","dir":"Articles","previous_headings":"","what":"Rotated Principal Components Analysis","title":"Pupilla::Advanced_statistical_analyses","text":"loadings can “rotated” : 1) interpretation easier (e.g., timepoints set closer 0, increased); 2) components orthogonal can correlate. result, model performs slightly worse terms explained variance, may allow one better, clearer interpretation loadings, may relax unrealistic assumption different components interact (correlate) significantly. implementation outlined . Please note reduce_PCA() follows prcomp(), function follows psych::principal() including standardization loadings (, even rotate \"none\" results differ slightly). ’s loadings now look:   , notwistanding differences implementation PCA - based covariance matrix psych::principal(), case second component clearly referring early part trial, presumably PLR.","code":"#the data data= DF2 #variables names should be supplied explicitly  dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" rotate= \"promax\" #oblique rotation #append to the reduced dataframe add= c(\"Set_size\", \"Color_type\")  rf2 = reduce_rPCA(   data = data,   dv = dv,   time = time,   id = id,   trial = trial,   rotate= rotate,   add = add ) ## Warning in reduce_rPCA(data = data, dv = dv, time = time, id = id, trial = trial, : NAs in the data will be discarded: ##             check the data! ## The determinant of the smoothed correlation was zero. ## This means the objective function is not defined. ## Chi square is based upon observed residuals. ## The determinant of the smoothed correlation was zero. ## This means the objective function is not defined for the null model either. ## The Chi square is thus based upon observed correlations. plot_loadings(\"RC1\", rf2) plot_loadings(\"RC2\", rf2)"},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"Pupilla::Advanced_statistical_analyses","text":"aim vignette present two main analytical approaches Pupilla. familiar enough domain original study adventure theoretical interpretations. Suffice say , opinion, crossvalidation approach appears replicate quite well - notwithstanding differences implementation - results reported authors. Furthermore, argument made utility consensus across folds enhance precision identifying temporal cluster. concerns second approach, .e. via feature reduction, also seen pretty coherent results. go far saying loadings PC1 can identify temporal cluster. sense, , though course dichotomic one, rather much graded, continuous one. care say , however, approach represent viable option collected data really huge, allow one obtain , much manageable variables can exploited sorts modelling purposes. Furthermore, variables may easy interpret - albeit , however, still better understand research.","code":""},{"path":"/articles/Pupilla_Advanced_statistical_analyses.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Pupilla::Advanced_statistical_analyses","text":"Packages’ versions:","code":"sessionInfo() ## R version 4.2.3 (2023-03-15 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19045) ##  ## Matrix products: default ##  ## locale: ## [1] LC_COLLATE=Italian_Italy.utf8  LC_CTYPE=Italian_Italy.utf8    LC_MONETARY=Italian_Italy.utf8 LC_NUMERIC=C                   LC_TIME=Italian_Italy.utf8     ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ##  [1] zoo_1.8-12         lmerTest_3.1-3     lme4_1.1-35.1      Matrix_1.6-5       emmeans_1.10.0     ggplot2_3.4.4      dplyr_1.1.4        usethis_2.2.2      pkgdown_2.0.7      Pupilla_0.0.0.9001 ##  ## loaded via a namespace (and not attached): ##  [1] tidyr_1.3.1         jsonlite_1.8.8      splines_4.2.3       askpass_1.2.0       highr_0.10          yaml_2.3.8          numDeriv_2016.8-1.1 pillar_1.9.0        lattice_0.22-5      glue_1.7.0          reticulate_1.35.0   digest_0.6.34       minqa_1.2.6         colorspace_2.1-0    sandwich_3.1-0      htmltools_0.5.7     psych_2.4.1         pkgconfig_2.0.3     purrr_1.0.2         xtable_1.8-4        gitcreds_0.1.2      mvtnorm_1.2-4       scales_1.3.0        processx_3.8.3      tibble_3.2.1        openssl_2.1.1       farver_2.1.1        generics_0.1.3      TH.data_1.1-2       cachem_1.0.8        withr_3.0.0         credentials_2.0.1   cli_3.6.2           mnormt_2.1.1        survival_3.5-3      magrittr_2.0.3      crayon_1.5.2        memoise_2.0.1       estimability_1.4.1  evaluate_0.23       ps_1.7.6            fs_1.6.3            fansi_1.0.6         nlme_3.1-162        MASS_7.3-58.2       ica_1.0-3           httr2_1.0.0         tools_4.2.3         gh_1.4.0            ## [50] lifecycle_1.0.4     multcomp_1.4-25     gert_2.0.1          munsell_0.5.0       callr_3.7.3         compiler_4.2.3      rlang_1.1.3         grid_4.2.3          nloptr_2.0.3        rstudioapi_0.15.0   sys_3.4.2           rappdirs_0.3.3      labeling_0.4.3      rmarkdown_2.25      boot_1.3-28.1       gtable_0.3.4        codetools_0.2-19    curl_5.2.0          R6_2.5.1            knitr_1.45          fastmap_1.1.1       utf8_1.2.4          rprojroot_2.0.4     desc_1.4.3          parallel_4.2.3      Rcpp_1.0.12         vctrs_0.6.5         png_0.1-8           tidyselect_1.2.0    xfun_0.41           coda_0.19-4.1"},{"path":"/articles/Pupilla_Assessing_Pupillary_Manifold.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Pupilla::Assessing_Pupillary_Manifold","text":"Pupilla gathers several functions designed facilitate analysis pupillometry experiments commonly performed cognitive neuroscience, e.g. event-related designs, although use much general. typical analysis pipeline , coarsely, include following steps: Read data. part can vary lot depending eyetracker used, individual OS, local paths, experiment coded, etc. Pupilla provide utility functions read common eyetrackers (e.g., TOBII, EyeLink) clearly passage need tailored files. Prepare data. , part may need tailored specific needs; however, several steps common across pipelines, presented vignette. Preprocessing. Pupillometry needs robust preprocessing raw data, order reduce noise artifacts (due blinks). data properly prepared, aspect can translated across several different scenarios. course, flexibility adapting data warmly advised. Statistical modelling. Pupilla offers two approaches: 1) crossvalidated LMEMs Mathôt & Vilotijević, 2022); 2) original approach feature/dimensionality reduction. vignette covers illustrates second option. particular, show mean “assessing pupillary manifold”, outlined accompanying paper. example use data Blini, Arrighi, Anobile, 2024. Data can retrieved full associated OSF repository. install Pupilla data included, however, actually find complete preprocessed data Exp 1 (“PLR” task) included package, extremely easy lead R (shown ). task asked 20 healthy, young participants passively watch matrix numbers change color/luminance level. Thus, data highlight well known Pupillary Light Response (PLR). aim vignette present temporal PCA rotated temporal PCA can implemented Pupilla.","code":""},{"path":"/articles/Pupilla_Assessing_Pupillary_Manifold.html","id":"read-the-data","dir":"Articles","previous_headings":"","what":"Read the data","title":"Pupilla::Assessing_Pupillary_Manifold","text":"library Pupilla must installed first, , devtools: Dependencies installed automatically. need load following packages: Reading data straightforward data come package: ’s ! Note recordings preprocessed already, including baseline subtraction. can plot results:  can see, brighter luminance, stronger pupil constriction, peak values 1-1.5 s, followed pupil escape.","code":"#install.packages(\"devtools\") devtools::install_github(\"EBlini/Pupilla\") library(\"Pupilla\") library(\"dplyr\") ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(\"ggplot2\")  options(dplyr.summarise.inform = FALSE) data(plr) plr$Luminance= as.factor(plr$Luminance)  colfunc <- colorRampPalette(c(\"black\", \"light gray\")) plr$Color= colfunc(8)[plr$Luminance]  plr %>%   group_by(Subject, Luminance, Time) %>%   summarise(Pupil= mean(Pupil), Color= Color[1]) %>%   #between   group_by(Luminance, Time) %>%   summarise(SEM= sd(Pupil)/sqrt(n()),             SEM= 1.96*SEM,             Pupil= mean(Pupil),             Color= Color[1]) %>%   ggplot(aes(x= Time, y= Pupil)) +   geom_vline(xintercept = c(0), linewidth= 1,              color= \"gray\", linetype= \"dashed\") +   geom_hline(yintercept = 0, linewidth= 1,              color= \"gray\", linetype= \"dashed\") +   geom_line(aes(color= Luminance),             linewidth= 1.2, show.legend = T) +   scale_color_manual(values = colfunc(8)) +   geom_ribbon(aes(ymin= Pupil-SEM,                  ymax= Pupil+SEM,                   fill= Luminance),              alpha= 0.2) +   scale_fill_manual(values = colfunc(8)) +   theme_bw() +   theme(text= element_text(size= 16,                            face=\"bold\",                            color= \"black\")) +   xlab(\"Time (ms)\") +   ylab(\"Pupil size change (z scores)\") +   ggtitle(\"PLR: changes in pupil size\") +    scale_x_continuous(breaks=c(0, 1500, 4500))"},{"path":[]},{"path":"/articles/Pupilla_Assessing_Pupillary_Manifold.html","id":"temporal-pca","dir":"Articles","previous_headings":"","what":"temporal PCA","title":"Pupilla::Assessing_Pupillary_Manifold","text":"Temporal PCA attempts summarise data fewer dimensions time maximizing amount information retained. scores can obtained way : 1. handy analyse 2. interpretable (see paper) 3. mindful factor “time” (weighted ) 4. fully data-driven, hence less arbitrary. Temporal PCA Pupilla implemented wrapper around stats::prcomp(), straightforward (data preprocessed). overly-sensitive reminder PCA works missing values timepoint. value within one recording missing, respective trial considered PCA. words: trials different length sampling rate without imputation/interpolation missing values, time points must . Apart , PCA Pupilla ends ! Let’s look object created way: object list following entries: “rs_mat” matrix used PCA, reference. probably need , ’s always good check whether matrix dimensions expect. future message may become informative / reassuring. “summaryPCA” summary returned prcomp(). components (rows data) together respective eigenvalues share explained variance. “Loadings” eigenvectors PCA Loadings (proper) rotated solutions. may perhaps changed future, e.g. “weights” enhanced compatibility. “Scores” , yes, Scores, “strength” one component low dimensional space. “PCA” object returned prcomp(). may need directly though useful prediction unobserved data, example (see, e.g., function Pupilla::predict_feature()). “scaling” information data scaling, relevant. mostly useful change default settings - normalize center data assume already baseline subtraction least - want predict new, untrained data (normalized according original values used model, see Pupilla::predict_feature()). typical pipeline, can start assessing relative contribution (explained variance) component. first one can account substantial share variability, almost 80%. several helper functions depict eigenvectors. depiction single components can use:  Else, can plot components together Pupilla::plot_fingerprints(). originally used term “fingerprints” assuming certain changes pupil size signature distinct physiological processes, though now lean toward thinking applicable rotated solutions (see ); , however, reserve term “pupillary manifold”, whereas “fingerprints” can perhaps general include sorts latent constructs, regardless origin. fact, function work temporal PCA, rotated PCA, Independent Components Analysis (ICA, coped , though functions ). catch: now function work Ncomp== 3; later , clearer .  function options reorder variables flip sign (note sign eigenvectors perfectly arbitrary PCA):  , probably want assess scores. Scores saved dataframe returned reduce_feature() object. additional experimental variables assess, can add piece information performing PCA add parameter. way, dataframe relevant information, can proceed modelling plotting directly dataframe provided.  can see first component latent dimension along PLR happens distinct strength, different luminance conditions well separable along dimension. scores reflect “strength PLR” also suggested shape eigenvector PC1 seen , reflects principled knowledge PLR look like. additionally map strength correlation objective luminance levels scores component.  conclude, temporal PCA represents handy approach, capable return , manageable values mindful temporal aspect. hand, discuss paper, approach used whenever fully confident process hand involves one (one major) process intend isolate. example, add sort Working Memory Load (WML) equation, different levels cognitive load hence associated psychosensory dilation, eigenvector first component still captures major axis variability, .e. mixture PLR WML effects, without dissociating two. discuss paper, point may want use approaches mindful temporal aspects, also underlying physiology. , refer “assessing pupillary manifold”.","code":"#this is not always necessary  #but do make sure that \"Time\" is properly ordered plr= plr %>%   arrange(Subject, trial, Time)    #you must include only timepoints with non-zero variance data= plr[plr$Time> 0,]  #for clarity, here's the variables needed dv= \"Pupil\" time = \"Time\"  id = \"Subject\" trial =  \"trial\" Ncomp = 3 #not very relevant for PCA add= c(\"Luminance\")  #Temporal PCA is actually only one function! plr_pca= reduce_PCA(data,                      dv= dv,                     time = time,                      id = id,                     trial =  trial,                     Ncomp= Ncomp,                     add= add) ## Warning in reduce_PCA(data, dv = dv, time = time, id = id, trial = trial, : NAs in the data will be discarded: ##             check the data! names(plr_pca) ## [1] \"rs_mat\"     \"summaryPCA\" \"Loadings\"   \"Scores\"     \"PCA\"        ## [6] \"scaling\" dim(plr_pca$rs_mat) ## [1] 869 449 #rows are all trials from all participants length(   unique(     interaction(plr$Subject, plr$trial))) ## [1] 869 #colums are the timepoints considered length(   unique(     plr$Time[plr$Time>0])) ## [1] 449 plr_pca$summaryPCA[,1:Ncomp] ##                             PC1      PC2      PC3 ## Standard deviation     30.88680 11.53209 7.752494 ## Proportion of Variance  0.78546  0.10950 0.049480 ## Cumulative Proportion   0.78546  0.89496 0.944440 plot_loadings(\"PC1\", plr_pca) plot_fingerprints(plr_pca) plot_fingerprints(plr_pca,                    order = \"peak\",                    flip = c(1, -1, 1)) ## Warning in plot_fingerprints(plr_pca, order = \"peak\", flip = c(1, -1, 1)): ## Warning: fingerprint names have been reordered following the explained ## variance! pca_scores= plr_pca$Scores %>%   group_by(id, Luminance) %>%   summarise(PC1= mean(PC1)) %>%   group_by(Luminance) %>%   summarise(SEM= sd(PC1)/sqrt(n()),             SEM= 1.96*SEM,             PC1= mean(PC1))  ggplot(pca_scores, aes(x = Luminance, y = PC1)) +   geom_segment(aes(     y = PC1 - SEM,     yend = PC1 + SEM,     xend = Luminance   ), linewidth = 1.2) +   geom_point(     aes(fill = as.factor(Luminance)),     shape = 21,     size = 5,     show.legend = F   ) +   scale_fill_manual(values = colfunc(8)) +   xlab(\"Luminance\") +   ylab(\"PC1 scores\") +   theme_bw() +   theme(     text = ggplot2::element_text(       size = 16,       face = \"bold\",       colour = \"black\"     ),     axis.text = element_text(colour = \"black\")   ) +   ggtitle(\"PLR: strength\") plr$Luminance=as.numeric(as.character(plr$Luminance))  pca_cor= plr_pca$Scores %>%   group_by(id, Luminance) %>%   summarise(PC1= mean(PC1)) %>%   group_by(id) %>%   summarise(R= cor(PC1, Luminance))  M= mean(pca_cor$R) SEM= sd(pca_cor$R)/sqrt(20)  ymax= M + 1.96*SEM ymin= M - 1.96*SEM  plr_mean= plr %>% filter(Time > 0) %>%    group_by(Subject, Time, Luminance) %>%    summarise(Pupil= mean(Pupil)) %>%    group_by(Subject, Time) %>%    summarise(R= cor(Pupil, Luminance)) %>%    group_by(Time) %>%   summarise(M= mean(R), SEM= sd(R)/sqrt(20))  ggplot(plr_mean, aes(x= Time, y= M)) +   geom_hline(yintercept = 0, linetype= \"dashed\") +   geom_rect(aes(xmin= 10, xmax= 4490,                  ymin= - ymin,                  ymax= - ymax),              fill= \"light blue\",              alpha= 0.3) +   geom_line() +   geom_line(aes(y= M - 1.96*SEM), color= \"red\")+   geom_line(aes(y= M + 1.96*SEM), color= \"red\") +   theme_bw() +   ylab(\"Pearson's R\") +    scale_x_continuous(breaks=c(0, 1500, 4500)) +     theme(text= ggplot2::element_text(size= 16,                                              face=\"bold\",                                              colour= \"black\"),                  axis.text= element_text(colour= \"black\")) +   ggtitle(\"PLR: timecourse\")"},{"path":"/articles/Pupilla_Assessing_Pupillary_Manifold.html","id":"rotated-pca","dir":"Articles","previous_headings":"","what":"Rotated PCA","title":"Pupilla::Assessing_Pupillary_Manifold","text":"rotated PCA implemented package wrappers around psych::principal(). Please note function, even absence rotations, produces slightly different results stats::prcomp() light several differences parametrization analytical approach. Please refer excellent psych package documentation differences psych::principal() psych::fa(). However, implementation rotated PCA extremely similar regular PCA. extra bit information required rotation type - default “promax”, . inevitably see many warnings psych. reading warnings harmless lamenting high dimensionality data, inability tell whether Ncomp solution appropriate given data. , differences returned object : model returned , course, based prcomp() principal() top PCA summary - still based prcomp - can find summaryRPCA, reporting information rotated solution. Notice overall explained variance 86%, instead 95% prcomp. also case rotate= \"none\", internal parameters principal(). can also see single components also changed share explained variance, time light rotation . account even share variance, .e. 39% rPC1 34% rPC2. can use set wrapper functions :  can assess scores well:  changes likely meaning scores.","code":"#again, just in case plr= plr %>%   arrange(Subject, trial, Time)    #you must include only timepoints with non-zero variance data= plr[plr$Time> 0,]  #for clarity, here's the variables needed dv= \"Pupil\" time = \"Time\"  id = \"Subject\" trial =  \"trial\" Ncomp = 3 #very relevant for rPCA add= c(\"Luminance\") rotate= \"promax\" #new!  #Temporal PCA is actually only one function! plr_rpca = reduce_rPCA(   data,   dv = dv,   time = time,   id = id,   trial =  trial,   Ncomp = Ncomp,   add = add,   rotate = rotate ) ## Warning in reduce_rPCA(data, dv = dv, time = time, id = id, trial = trial, : NAs in the data will be discarded: ##             check the data! ## Warning in cor.smooth(r): Matrix was not positive definite, smoothing was done ## The determinant of the smoothed correlation was zero. ## This means the objective function is not defined. ## Chi square is based upon observed residuals. ## The determinant of the smoothed correlation was zero. ## This means the objective function is not defined for the null model either. ## The Chi square is thus based upon observed correlations. ## Warning in psych::principal(rs_mat, nfactors = Ncomp, rotate = rotate): The ## matrix is not positive semi-definite, scores found from Structure loadings names(plr_rpca) ## [1] \"rs_mat\"      \"summaryPCA\"  \"summaryRPCA\" \"Loadings\"    \"Scores\"      ## [6] \"rPCA\"        \"scaling\" plr_rpca$summaryRPCA ##                               RC1         RC2        RC3 ## SS loadings           176.4576950 151.1138267 59.6308080 ## Proportion Var          0.3930015   0.3365564  0.1328080 ## Cumulative Var          0.3930015   0.7295580  0.8623660 ## Proportion Explained    0.4557248   0.3902710  0.1540043 ## Cumulative Proportion   0.4557248   0.8459957  1.0000000 plot_fingerprints(plr_rpca) rpca_scores= plr_rpca$Scores %>%   group_by(id, Luminance) %>%   summarise(RC3= mean(RC3)) %>%   group_by(Luminance) %>%   summarise(SEM= sd(RC3)/sqrt(n()),             SEM= 1.96*SEM,             RC3= mean(RC3))  ggplot(rpca_scores,         aes(x = Luminance, y = RC3)) +   geom_segment(aes(     y = RC3 - SEM,     yend = RC3 + SEM,     xend = Luminance   ), linewidth = 1.2) +   geom_point(     aes(fill = as.factor(Luminance)),     shape = 21,     size = 5,     show.legend = F   ) +   scale_fill_manual(values = colfunc(8)) +   xlab(\"Luminance\") +   ylab(\"RC3 scores\") +   theme_bw() +   theme(     text = ggplot2::element_text(       size = 16,       face = \"bold\",       colour = \"black\"     ),     axis.text = element_text(colour = \"black\")   ) +   ggtitle(\"Parasymphatetic\\nactivation strength\")"},{"path":"/articles/Pupilla_Assessing_Pupillary_Manifold.html","id":"the-pupillary-manifold","dir":"Articles","previous_headings":"","what":"The Pupillary Manifold","title":"Pupilla::Assessing_Pupillary_Manifold","text":"discuss thoroughly paper, rotated solution returns set loadings extremely constant across different tasks. sense unlikely reflect something idiosyncratic data. contrary, loadings likely reflect hard constraints underlying physiology signal . suggestion made three components recovered way reflect physiologically relevant processes: RC1: symphatetic activation RC2: parasymphatetic inhibition RC3: parasymphatetic activation relative scores define pupil traces lie (coordinates) low-dimensional space reflecting overall balance autonomic nervous system. Thus, top handy analyze, mindful temporal aspects, completely data-driven, , values also physiologically meaningful. toolbox comes wrapper functions 3D plots plot3D, installed default package - plot3D installed manually.  Finally, gifski (installed automatically) provides utilities create GIFs several different images. function animate_manifold() precisely : creates folder populated many plot_manifold() images taken different views, saves gif image current path.","code":"plr_rpca$Scores$Luminance= as.factor(plr_rpca$Scores$Luminance) plot_manifold(plr_rpca$Scores,               colvar = \"Luminance\",                theta = 30, phi= 15) ## Warning: no DISPLAY variable so Tk is not available"},{"path":"/articles/Pupilla_Assessing_Pupillary_Manifold.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Pupilla::Assessing_Pupillary_Manifold","text":"Packages’ versions:","code":"sessionInfo() ## R version 4.4.2 (2024-10-31) ## Platform: x86_64-pc-linux-gnu ## Running under: Ubuntu 24.04.1 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 ##  ## locale: ##  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        ##  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    ##  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           ## [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    ##  ## time zone: UTC ## tzcode source: system (glibc) ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] ggplot2_3.5.1    dplyr_1.1.4      Pupilla_0.1.1.01 ##  ## loaded via a namespace (and not attached): ##  [1] gtable_0.3.6      jsonlite_1.8.9    compiler_4.4.2    plot3D_1.4.1      ##  [5] psych_2.4.12      tidyselect_1.2.1  parallel_4.4.2    jquerylib_0.1.4   ##  [9] systemfonts_1.1.0 scales_1.3.0      textshaping_0.4.1 yaml_2.3.10       ## [13] fastmap_1.2.0     lattice_0.22-6    R6_2.5.1          tcltk_4.4.2       ## [17] labeling_0.4.3    generics_0.1.3    knitr_1.49        misc3d_0.9-1      ## [21] tibble_3.2.1      desc_1.4.3        munsell_0.5.1     bslib_0.8.0       ## [25] pillar_1.10.1     rlang_1.1.4       cachem_1.1.0      xfun_0.50         ## [29] fs_1.6.5          sass_0.4.9        cli_3.6.3         pkgdown_2.1.1     ## [33] withr_3.0.2       magrittr_2.0.3    digest_0.6.37     grid_4.4.2        ## [37] nlme_3.1-166      lifecycle_1.0.4   vctrs_0.6.5       mnormt_2.1.1      ## [41] evaluate_1.0.3    glue_1.8.0        farver_2.1.2      ragg_1.3.3        ## [45] colorspace_2.1-1  rmarkdown_2.29    tools_4.4.2       pkgconfig_2.0.3   ## [49] htmltools_0.5.8.1"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Pupilla::EyeLink::Read_and_preprocess","text":"Pupilla gathers several functions designed facilitate analysis pupillometry experiments commonly performed cognitive neuroscience, e.g. event-related designs, although use much general. typical analysis pipeline , coarsely, include following steps: Read data. part can vary lot depending eyetracker used, individual OS, local paths, experiment coded, etc. Pupilla provide utility functions read common eyetrackers (e.g., TOBII, EyeLink) clearly passage need tailored files. Prepare data. , part may need tailored specific needs; however, several steps common across pipelines, presented vignette. Preprocessing. Pupillometry needs robust preprocessing raw data, order reduce noise artifacts (due blinks). data properly prepared, aspect can translated across several different scenarios. course, flexibility adapting data warmly advised. Statistical modelling. Pupilla offers two approaches: 1) crossvalidated LMEMs Mathôt & Vilotijević, 2022); 2) original approach feature reduction. vignette cover analysis step. vignette focus read preprocess data single participant, tested EyeLink 1000. multiple differences may arise pipeline, according specific rationale experiment difference coding implementation. functions written OpenSesame mind. example use data Blini et al., 2023. Data can retrieved associated OSF repository. study 70 participants (following exclusions) given arithmetic task, preceded auditory cue (“easy” “hard”) prompting corresponding difficulty. response phase variable length, given auditory feedback. , trial lasted several seconds. Details provided accompanying paper, matters participants found pupillary dilation depending trial difficulty, classic result. focus data one participant. Please note pipeline default parameters Pupilla changing early development phase, results may slightly different reported elsewhere.","code":""},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"read-the-data","dir":"Articles","previous_headings":"","what":"Read the data","title":"Pupilla::EyeLink::Read_and_preprocess","text":"library Pupilla must installed first, , devtools: Dependencies installed automatically. need load following packages: following steps section vary lot function software used presentation stimuli machine. Pupilla tested windows machines, may thus troubles using utility functions read participants altogether. Windows: can see: working directory set - change !; ask specific participant , vector IDs supplied; participant comes two files default OpenSesame splits eyetracker behavioral files. supplied directly character vector events - defined OpenSesame script) included relevant phases trial. datapoints belong phases kept. mandatory stage. , reading files straightforward. utility function work , however, just assume works iterating eyelinkReader::read_edf() across (eyetracking) files. order use excellent eyelinkReader package, must installed SR research-EyeLink plugins, can download forum upon registration (functions also needed control eyelink).","code":"#install.packages(\"devtools\") devtools::install_github(\"EBlini/Pupilla\") library(\"Pupilla\") library(\"dplyr\")  library(\"ggplot2\")  library(\"tidyr\")  options(dplyr.summarise.inform = FALSE) #set your own working directory first! #wd= choose.dir()  subject= 10 #vector of ids; only 1 for this example  #as coded in the program - these are the relevant eyelink messages keep_events = c(   \"fixation\",   \"cue\",   \"target1\",   \"sign\",   \"target2\",   \"calculation\",   \"response\",   \"post_resp_fix\",   \"Wait_Feedback\",   \"feedback\" )  #read  data= read_eyelink(subject, keep_events,                     path = wd)  #split for eyetracker and behavioral data ET= data$ET BD= data$BD  ET$Subject= subject BD$Subject= subject"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"prepare-the-data","dir":"Articles","previous_headings":"","what":"Prepare the data","title":"Pupilla::EyeLink::Read_and_preprocess","text":"bad (?) habit record essential info eyetracker file, :) result, often variables present behavioral file (e.g., response time, condition) must copied eyetracker file, different dimensions (several lines per trial, depending sampling rate). Pupilla utility functions precisely . Specifically, behavioral data (BD) report variables Phase, Accuracy, Cue, etc. discard practice trials: experiment, recording left eye . thus set Pupil area corresponding variable: set NA Pupil values 0. mandatory preprocessing functions follow. Also, although often automatic, retain data samples fixation recorded eyelink. Next, generally remove values exceed certain threshold, e.g. < - 2.5 standard deviation subject’s mean (considering samples). can now realign timestamps first sample initial phase. , downsample 20 ms bins.","code":"#whether it's practice or experiment ET$Phase = copy_variable(   \"Phase\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) #result of the problem ET$Result = copy_variable(   \"Result\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) #response ET$Response = copy_variable(   \"response\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) #set accuracy ET$Accuracy = ifelse(ET$Response == ET$Result,                      \"correct\",                      \"incorrect\") #condition ET$Cue = copy_variable(   \"Cue\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) ET= ET[ET$Phase== \"experiment\",] BD= BD[BD$Phase== \"experiment\",] ET$Pupil= ET$paL #very important, set zeros to NA for preprocessing ET$Pupil= ifelse(ET$Pupil==0, NA, ET$Pupil)  ET$Pupil[ET$is_Fixation==0]= NA cut_off= mean(ET$Pupil, na.rm= T) - 2.5*sd(ET$Pupil, na.rm= T) ET$Pupil= ifelse(ET$Pupil < cut_off, NA, ET$Pupil) ET= ET %>%    group_by(trial) %>%    mutate(Time= time-time[Event== \"fixation\"][1])"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"preprocessing","dir":"Articles","previous_headings":"","what":"Preprocessing","title":"Pupilla::EyeLink::Read_and_preprocess","text":"can finally move real thing! signal must processed impact artifacts, blinks, etc. reduced. easiest way Pupilla use pre_process() function. may want, however, consider whether specific default parameters applicable data. description parameters, see ?pp_options(). can always change default parameters calling options globally, within function . E.g.: checked defaults, preprocessing requires: ’s ! can check result pipeline visually follows:  can use function Pupilla::check_all_series() plots (, ids trials) saved images path. image, black dots represent raw, initial data. red line depicts instead reconstructed, preprocessed signal. pre_process() simply runs, order, functions deblinking (velocity-based criterion), interpolation, smoothing cubic splines. Trials data points reach given quality threshold set NA; trials can recovered , instead, recovered. , trials couldn’t restore reliable signal, simply discard ! Another common step downsampling, choose bins 20 ms: Next, personally prefer work z-scores instead arbitrary units mms, standardized measure. : particular case include response phase motor artifacts (verbal response blinks allowed), alter much pattern results. needed, can remove trials starting pupil size particularly extreme. last, crucial step baseline subtraction. analogy done paper simply realign traces median fixation phase. done! One way save preprocessed files : way group analysis faster. depict data particular participant.","code":"#the default parameters: pp_options() ## $thresh ## [1] 3 ##  ## $speed_method ## [1] \"z\" ##  ## $extend_by ## [1] 25 ##  ## $island_size ## [1] 4 ##  ## $extend_blink ## [1] 25 ##  ## $overall_thresh ## [1] 0.4 ##  ## $consecutive_thresh ## NULL ##  ## $spar ## [1] 0.8 pp_options(\"extend_by\"= 25) #strip 50 ms before and after blinks pp_options(\"extend_blink\"= 25) #further extend prior to interpolation pp_options(\"spar\"= 0.8) #smoothing parameter #entire preprocessing ET= ET %>%   group_by(Subject, trial) %>%   mutate(Pupil_pp= pre_process(Pupil, Time)) ET %>% filter(Subject==10 & trial== 13) %>%   check_series(\"Pupil\", \"Pupil_pp\", \"Time\") #drop ET= ET %>% filter(!is.na(Pupil_pp)) ET$Time= downsample_time(ET$Time, 20)  #summarise the data for the new binned variable ET= ET %>%   group_by(Subject, Cue, Event,             trial, Time, Accuracy) %>%   summarise(Pupil= median(Pupil_pp, na.rm = T)) #z scores ET$Pupil_raw= ET$Pupil  ET= ET %>%   group_by(Subject, trial) %>%   mutate(Pupil= ((Pupil - mean(Pupil[Event!= \"response\"]))/sd(Pupil[Event!= \"response\"]))) deviant_baseline= ET %>%    group_by(Subject, trial) %>%   summarise(Baseline_ps= median(Pupil[Event== \"fixation\"], na.rm=T))   deviant_baseline$Baseline_ps= scale(deviant_baseline$Baseline_ps)  #to omit omit= deviant_baseline$trial[abs(deviant_baseline$Baseline_ps)>2]  omit= na.omit(omit)  if(length(omit)>0){   ET= ET %>% filter(!trial %in% omit) } ET= ET %>%   group_by(Subject, trial) %>%   mutate(Pupil= Pupil - median(Pupil[Event== \"fixation\"])) #save preprocessed data for modelling ppdataaddress= paste0(\"pp_data//subj_\", subj, \".RDS\")     saveRDS(ET, file = ppdataaddress)"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Pupilla::EyeLink::Read_and_preprocess","text":"Packages’ versions:","code":"sessionInfo()"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Pupilla::TOBII::Reduce_Features","text":"Pupilla gathers several functions designed facilitate analysis pupillometry experiments commonly performed cognitive neuroscience, e.g. event-related designs, although use much general. typical analysis pipeline , coarsely, include following steps: Read data. part can vary lot depending eyetracker used, individual OS, local paths, experiment coded, etc. Pupilla provide utility functions read common eyetrackers (e.g., TOBII, EyeLink) clearly passage need tailored files. Prepare data. , part may need tailored specific needs; however, several steps common across pipelines, presented vignette. Preprocessing. Pupillometry needs robust preprocessing raw data, order reduce noise artifacts (due blinks). data properly prepared, aspect can translated across several different scenarios. course, flexibility adapting data warmly advised. Statistical modelling. Pupilla offers two approaches: 1) crossvalidated LMEMs Mathôt & Vilotijević, 2022); 2) original approach feature reduction. vignette covers illustrates second option. example use data Blini Zorzi, 2023. Data can retrieved associated OSF repository. eyetracker used TOBII spectrum. Unfortunately, eyetracking data acquired way quite large, meaning reading take time. study (termed Passive Viewing (PV) task) 40 participants (following exclusions), 20 smokers 20 non smokers, given, name suggests, several images look : related nicotine, neutral controls. Contrary name suggest, instead, also report (hence somehow actively) occurrence rare probe, presented screen sparingly; ensure central fixation maintained together minimum task engagement. Details provided accompanying paper, matters smokers found pupillary constriction nicotine-related images (opposed neutral ones) presented. Please note pipeline default parameters Pupilla changed since paper came PBR, results slightly different.","code":""},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"read-the-data","dir":"Articles","previous_headings":"","what":"Read the data","title":"Pupilla::TOBII::Reduce_Features","text":"library Pupilla must installed first, , devtools: Dependencies installed automatically. need load following packages: following steps section vary lot function software used presentation stimuli machine. Pupilla tested windows machines, may thus troubles using utility functions read participants altogether. Windows: can see: working directory set - change !; 51 subjects corresponding 102 files default OpenSesame splits eyetracker behavioral files. , reading files straightforward. utility function work , however, just assume works iterating data.table::fread() across (eyetracking) files. Also, please note default first 7 lines skipped, eyetracker files may need different values!","code":"#install.packages(\"devtools\") devtools::install_github(\"EBlini/Pupilla\") library(\"Pupilla\") library(\"dplyr\")  #  # Attaching package: 'dplyr' # The following objects are masked from 'package:stats': #  #     filter, lag # The following objects are masked from 'package:base': #  #     intersect, setdiff, setequal, union library(\"ggplot2\")  library(\"tidyr\")  options(dplyr.summarise.inform = FALSE) #set your own working directory first! #wd= choose.dir()  subject= 1:51 #vector of ids #groups- whether ids are smokers or not;  #this I didn't know beforehand so I have to add manually this var group= c(\"NS\", \"S\", \"NS\", \"NS\", \"S\",\"S\", \"NS\", \"S\",          \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"NS\", \"S\",          \"NS\", \"S\", \"NS\", \"S\", \"NS\", \"NS\", \"S\", \"NS\",          \"S\", \"NS\", \"NS\", \"NS\", \"NS\", \"NS\", \"NS\", \"S\",          \"S\", \"S\", \"S\", \"NS\", \"NS\", \"NS\", \"NS\", \"S\",          \"NS\", \"NS\", \"NS\", \"S\", \"S\", \"S\", \"S\", \"S\",          \"S\", \"S\", \"S\")  #read all the files data= read_TOBII(subject, wd)  #split for eyetracker and behavioral data ET= data$ET BD= data$BD"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"prepare-the-data","dir":"Articles","previous_headings":"","what":"Prepare the data","title":"Pupilla::TOBII::Reduce_Features","text":"bad (?) habit record essential info eyetracker file, :) result, often variables present behavioral file (e.g., response time, condition) must copied eyetracker file, different dimensions (several lines per trial, depending sampling rate). Pupilla utility functions precisely . Let’s move order though. start filling “Event” column, blank except Event changes: Based Event column changing value, can establish trial number (yes, info also missing eyetracker file!). detect_change() simply updates counter every instance parameter “key” appears vector (first time). initial samples assigned trial, shall removed: can start now copying relevant variables ET dataframe. start adding variable Phase (whether trial labelled practice, therefore removed afterwards, experimental). move variable Trial: finally variables make experimental design: (, Condition relevant , rest can skip vignette). can finally start handling preparing signal pupil size! TOBII acquired left right eye. consolidate two one single variable represents average two eyes - judged valid TOBII’s algorithms. TOBII stores pupil size mms, can fetch plausible values (2 7 mms) discard outlier ones straight away. isolate two experimental stages: scrambled images (baseline) vs target images. can now realign timestamps first sample scrambled phase. can see timestamps absolute values, difference really constant. theory trial last 4500 ms, one two reasons missed something last longer, shall discard . Now everything clean, realign Time beginning trial, moment target presented: Finally, moment Group variable added. Furthermore, discard participants present sufficient valid trials; actually seen afterwards, experiment add another task eye movements quality important, exclusions decided based results tasks.","code":"ET$Event= ifelse(ET$Event== \"\", NA, ET$Event) ET= tidyr::fill(ET, Event, .direction = \"down\") ET$Subject= ET$p_ID ET= ET %>%   group_by(Subject) %>%   mutate(Trial= detect_change(Event,                                key= \"scrambled\")) ET= ET[ET$Trial>=0,] #whether it's practice or experiment ET$Phase= copy_variable(\"Phase\") #discard practice ET= ET[ET$Phase== \"experiment\",] BD= BD[BD$Phase== \"experiment\",] ET$Trial= copy_variable(\"Trial\") ET$Condition= copy_variable(\"Condition\") # ET$Cue= copy_variable(\"Cue\") # ET$Accuracy= copy_variable(\"Accuracy\") # ET$Image= copy_variable(\"Image\") # ET$RT = as.numeric(copy_variable(\"RT\")) ET$Pupil= consolidate_signal(ET$PupilSizeLeft, ET$PupilSizeRight,                              ET$PupilValidityLeft, ET$PupilValidityRight,                              strategy = \"conservative\",                              plausible= c(2, 7)) ET= ET[ET$Event %in% c(\"scrambled\", \"target\"),] #head(ET$TimeStamp)  ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Time= c(0,                  cumsum(diff(TimeStamp))))  #head(ET$Time) #range(ET$Time)  ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Anomaly= ifelse(max(Time)>4500, 1, 0))  # (table(ET$p_ID[ET$Anomaly== 1],  #       ET$Trial[ET$Anomaly== 1])) #for 1 participant, the trial around the break...  ET= ET[ET$Anomaly== 0,] ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Time= Time - Time[Event== \"target\"][1])  ET= ET[ET$Time >-1000 & ET$Time<3000,] ET= ET %>% filter(!Subject %in% c(2, 9, 10, 13, 25, 29, 30, 34, 38, 48, 49))  #assign group ET$Group= group[ET$Subject]"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"preprocessing","dir":"Articles","previous_headings":"","what":"Preprocessing","title":"Pupilla::TOBII::Reduce_Features","text":"can finally move real thing! signal must processed impact artifacts, blinks, etc. reduced. easiest way Pupilla use pre_process() function. may want, however, consider whether specific default parameters applicable data. description parameters, see ?pp_options(). can always change default parameters calling options globally, within function . E.g.: checked defaults, preprocessing requires: ’s ! can check result pipeline visually follows:  can use function Pupilla::check_all_series() plots (, ids trials) saved images path. image, black dots represent raw, initial data. red line depicts instead reconstructed, preprocessed signal. pre_process() simply runs, order, functions deblinking (velocity-based criterion), interpolation, smoothing cubic splines. Trials data points reach given quality threshold set NA; trials can recovered , instead, recovered. , trials couldn’t restore reliable signal, simply discard ! Another common step downsampling, choose bins 25 ms: Next, personally prefer work z-scores instead arbitrary units mms, standardized measure. : last, crucial step baseline subtraction. analogy done paper simply realign traces beginning target presentation phase, just like done Time. extended period advisable. done!","code":"#the default parameters: pp_options() # $thresh # [1] 3 #  # $speed_method # [1] \"z\" #  # $extend_by # [1] 3 #  # $island_size # [1] 4 #  # $extend_blink # [1] 3 #  # $overall_thresh # [1] 0.4 #  # $consecutive_thresh # NULL #  # $spar # [1] 0.7  #this changes the width of the window for smoothing pp_options(\"spar\"= 0.8) #entire preprocessing ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Pupil_pp= pre_process(Pupil, Time)) ET %>% filter(Subject==12 & Trial== 104) %>%   check_series(\"Pupil\", \"Pupil_pp\", \"Time\") #drop ET= ET %>% filter(!is.na(Pupil_pp)) ET$Time= downsample_time(ET$Time, 25)  #summarise the data for the new binned variable ET= ET %>%   group_by(Subject, Group, Condition, Trial, Time) %>%   summarise(Pupil= median(Pupil_pp, na.rm = T)) ET= ET %>%   group_by(Subject) %>%   mutate(Pupil= (Pupil-mean(na.omit(Pupil)))/sd(na.omit(Pupil))) ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Pupil= Pupil - Pupil[Time== 0][1])"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"analysis","dir":"Articles","previous_headings":"","what":"Analysis","title":"Pupilla::TOBII::Reduce_Features","text":"Briefly, data looks like :  now different paths statistical modelling. original paper choose cluster-based permutation test. approach often computationally-intensive, though works well. approaches involve crossvalidated LMEMs (implemented package Pupilla shown another vignette) feature reduction. Feature reduction norm pupillometry, common branches neuroimaging - e.g., fMRI. works well, data large, reducing dimensions manageable variables work . case pupillometry, signal strongly autocorrelated, particularly appealing. Pupilla can summarise traces PCA ICA follows.","code":""},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"pca","dir":"Articles","previous_headings":"Analysis","what":"PCA","title":"Pupilla::TOBII::Reduce_Features","text":"traces 40 participants x () 200 trials can summarised PCs (need 3 variables account >98% data!): PC accounts specific share variance, distinctive loadings - can think weighted contribution PC time point, way similar cluster, though graded. can assess loadings directly plot conveniently returned plot_loadings().  loadings first PC, expected, resemble much shape data. trial steady pupil dilation, well captured later timepoints larger weights. sign loadings , instead, arbitrary, well multiply -1. component summarised one score per trial! far manageable uses, e.g. obtain intuitive easy interpret summary scores. Scores can used directly - e.g., correlate experimental variables questionnaires neuroimaging data - used second level analysis (e.g., simple t tests). case Group x Condition interaction, start summarising trial summary scores, scoring difference conditions: PC1:  significant interaction group condition captured first PC! second PC , instead, significant: Features first ones progressively account remaining variance, may thus accomodate subtle differences conditions alter necessarily overall shape pupillary dilation. words, next pcs describe sort contrast functions like one:","code":"data= ET[ET$Time>0,] #remove the baseline dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" add= c(\"Group\", \"Condition\") #save to final dataframe Ncomp= NULL #defaults to 95% of variance retained  rf = reduce_PCA(data,                 dv,                 time,                 id,                 trial,                 Ncomp = NULL,                 add) rf$summaryPCA[, 1:4] plot_loadings(\"PC1\", rf) Scores= rf$Scores  Scores= Scores %>%    group_by(id, Group, Condition) %>%    summarise(PC1= mean(PC1), PC2= mean(PC2)) %>%    group_by(id, Group) %>%    reframe(PC1= PC1[Condition== \"Control\"]-PC1[Condition== \"Nicotine-related\"],            PC2= PC2[Condition== \"Control\"]-PC2[Condition== \"Nicotine-related\"]) #plots of the difference ggplot(Scores, aes(x= Group,                    color= Group,                    y= PC1)) +   geom_point(position = position_dodge2(0.3))   t.test(Scores$PC1[Scores$Group== \"Smokers\"],        Scores$PC1[Scores$Group== \"Non smokers\"]) t.test(Scores$PC2[Scores$Group== \"Smokers\"],        Scores$PC2[Scores$Group== \"Non smokers\"]) plot_loadings(\"PC2\", rf)"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"ica","dir":"Articles","previous_headings":"Analysis","what":"ICA","title":"Pupilla::TOBII::Reduce_Features","text":"Choosing ICA simple ! Pupilla uses ica::icafast independent components analysis. overall explained variance remains PCA. However, single contribution components weighted : words, trust much title loadings plot - refers PCA model:  case first IC first PC similar, scale changes bit, reflect overall dilation trend - , sign loadings really matter (just check direction interpretation data). Results (somehow) similar PCA:","code":"rf2 = reduce_ICA(data,                  dv,                  time,                  id,                  trial,                  Ncomp = NULL,                  center = F,                  add) rf2$ICA$vafs plot_loadings(\"IC1\", rf2) Scores2= rf2$Scores  Scores2= Scores2 %>%    group_by(id, Group, Condition) %>%    summarise(IC1= mean(IC1), IC2= mean(IC2)) %>%    group_by(id, Group) %>%    reframe(IC1= IC1[Condition== \"Control\"]-IC1[Condition== \"Nicotine-related\"],            IC2= IC2[Condition== \"Control\"]-IC2[Condition== \"Nicotine-related\"]) #plots of the difference ggplot(Scores2, aes(x= Group,                    color= Group,                    y= IC1)) +   geom_point(position = position_dodge2(0.3))  t.test(Scores2$IC1[Scores$Group== \"Smokers\"],        Scores2$IC1[Scores$Group== \"Non smokers\"])"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Pupilla::TOBII::Reduce_Features","text":"vignette went example use functions Pupilla data, areas encompassing loading, preparing, preprocessing data. Furthermore, novel approach - , , object active research - analyze data presented. approach signal decomposed , manageable scores, explain efficiently (severely autocorrelated) data handful scores. scores can attributed differences pupil size different time points, can explored visually loadings specific components. Another advantage , case multiple components presenting significant effects, weights can backprojected linear combination coefficients loadings (see, details, backprojection package, FCnet). approach therefore potential flexible. approach discussed details accompanying paper.","code":""},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Pupilla::TOBII::Reduce_Features","text":"Packages’ versions:","code":"sessionInfo() # R version 4.2.3 (2023-03-15 ucrt) # Platform: x86_64-w64-mingw32/x64 (64-bit) # Running under: Windows 10 x64 (build 19045) #  # Matrix products: default #  # locale: # [1] LC_COLLATE=Italian_Italy.utf8  LC_CTYPE=Italian_Italy.utf8    LC_MONETARY=Italian_Italy.utf8 LC_NUMERIC=C                   LC_TIME=Italian_Italy.utf8     #  # attached base packages: # [1] stats     graphics  grDevices utils     datasets  methods   base      #  # other attached packages: # [1] tidyr_1.3.0        ggplot2_3.4.1      dplyr_1.1.0        Pupilla_0.0.0.9000 #  # loaded via a namespace (and not attached): #  [1] Rcpp_1.0.10         nloptr_2.0.3        pillar_1.8.1        compiler_4.2.3      tools_4.2.3         boot_1.3-28.1       digest_0.6.31       lme4_1.1-32         nlme_3.1-162        evaluate_0.20       lifecycle_1.0.3     tibble_3.2.0        gtable_0.3.1        lattice_0.20-45     pkgconfig_2.0.3     rlang_1.1.3         Matrix_1.5-3        cli_3.6.0           rstudioapi_0.14     patchwork_1.1.2     yaml_2.3.7          xfun_0.39           fastmap_1.1.1       withr_2.5.0         knitr_1.42          generics_0.1.3      vctrs_0.6.0         lmerTest_3.1-3      grid_4.2.3          tidyselect_1.2.0    glue_1.6.2          R6_2.5.1            fansi_1.0.4         rmarkdown_2.20      minqa_1.2.5         purrr_1.0.1         magrittr_2.0.3      settings_0.2.7      scales_1.2.1        htmltools_0.5.4     MASS_7.3-58.2       splines_4.2.3       colorspace_2.1-0    numDeriv_2016.8-1.1 utf8_1.2.3          munsell_0.5.0"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Elvio Blini. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blini E (2025). Pupilla: Process Analyze Eye-tracking Pupillometry Data. R package version 0.1.1.01, https://github.com/EBlini/Pupilla.","code":"@Manual{,   title = {Pupilla: Process and Analyze Eye-tracking and Pupillometry Data},   author = {Elvio Blini},   year = {2025},   note = {R package version 0.1.1.01},   url = {https://github.com/EBlini/Pupilla}, }"},{"path":"/index.html","id":"pupilla","dir":"","previous_headings":"","what":"Process and Analyze Eye-tracking and Pupillometry Data","title":"Process and Analyze Eye-tracking and Pupillometry Data","text":"R package processing analysis eye-tracking pupillometry data.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Process and Analyze Eye-tracking and Pupillometry Data","text":"package currently available GitHub. installation requires R package remotes.","code":"# install.packages(\"remotes\") remotes::install_github(\"EBlini/Pupilla\")"},{"path":"/index.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Process and Analyze Eye-tracking and Pupillometry Data","text":"collection functions wrappers useful preprocessing analysis eyetracking data, special focus pupillometry. Functions generally hardware-agnostic, designed data collected third-part experiment builders OpenSesame. Functions tested Windows machines. functions considered development: requests suggestions welcome, :) . Manuals, references, vignettes available link: https://eblini.github.io/Pupilla/ useful references, example results functions, see Blini Zorzi, 2023 Blini, Arrighi, Anobile, 2024.","code":""},{"path":"/reference/animate_manifold.html","id":null,"dir":"Reference","previous_headings":"","what":"Animate a 3D scatterplot (based on plot3D) through gifski — animate_manifold","title":"Animate a 3D scatterplot (based on plot3D) through gifski — animate_manifold","text":"function executes plot_manifold, inherits parameters, iteratively, saves frame folder current path, creates gif package gifski, must installed.","code":""},{"path":"/reference/animate_manifold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Animate a 3D scatterplot (based on plot3D) through gifski — animate_manifold","text":"","code":"animate_manifold(   Scores,   colvar = NULL,   col = NULL,   gifname = \"gif.gif\",   thetas = seq(0, 359, 1),   phis = rep(10, 360),   pch = 16,   cex = 2,   xlim = NULL,   ylim = NULL,   zlim = NULL,   adapt3D = F,   width = 700,   height = 700,   delay = 75/1000 )"},{"path":"/reference/animate_manifold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Animate a 3D scatterplot (based on plot3D) through gifski — animate_manifold","text":"Scores object returned 'reduce_rPCA'. gifname Name gif file saved current path adapt3D Whether axis \"\", FALSE, strectched fit 3D box, TRUE delay Speed transitions seconds colvar;col name variable use colors; char vectors colors. thetas;phis angles \"eyes\" plot given vectors angles form gif. Vectors must length pch;cex graphical pars defining shape size points plotted xlim;ylim;zlim manually supply limits width;height Dimensions images thus gif","code":""},{"path":"/reference/animate_manifold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Animate a 3D scatterplot (based on plot3D) through gifski — animate_manifold","text":"gif saved current path; side effect: frames saved folder path.","code":""},{"path":"/reference/check_all_series.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"Convenience function check series across IDs Trials, saves multiple plots current path creating folders subfolders hopefully meaningful way. Note massive data take time, may want debug first subset data. defaults 'ggsave', used internally, now bit stiff may become flexible future. 'check_series' function invoked plots, thus may want check relative help page.","code":""},{"path":"/reference/check_all_series.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"","code":"check_all_series(data, ID, Trial, series1, series2, time)"},{"path":"/reference/check_all_series.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"data Mandatory, differently 'check_series'. IDs Trials levels around loop set retrieved . ID string indicating name ID column. Trial string indicating name Trial column. series1 Unlike 'check_series', must string indicating name first time series plot. series2 Unlike 'check_series', must string indicating name second time series plot. time Unlike 'check_series', must string indicating elapsed time, used x-axis.","code":""},{"path":"/reference/check_all_series.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"plot.","code":""},{"path":"/reference/check_series.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots two time series against each other — check_series","title":"Plots two time series against each other — check_series","text":"function plots two time series . intended use generally check original vs. preprocessed data. first series plotted black line, second one - typically reconstructed series - red line. Nas show interruptions lines. function can used within dplyr's style pipes - case 'data' can omitted variables must provided quoted variables' names - standard vectors may provided - case 'data' NULL args passed name.","code":""},{"path":"/reference/check_series.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots two time series against each other — check_series","text":"","code":"check_series(data, series1, series2, time)"},{"path":"/reference/check_series.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots two time series against each other — check_series","text":"data Optional. Can omitted passed dplyr's style pipelines ('.'), case arguments passed quoted variables' names. series1 vector variable values first time series. plotted means black line. Typically, original data. series2 vector variable values second time series. plotted means red line. Typically, processed data. time vector variable indicating elapsed time, used x axis.","code":""},{"path":"/reference/check_series.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots two time series against each other — check_series","text":"plot.","code":""},{"path":"/reference/consolidate_signal.html","id":null,"dir":"Reference","previous_headings":"","what":"Consolidate pupil data according to different heuristics — consolidate_signal","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"Mostly used, e.g., pupil data available eyes one needs single variable. Results weighted vectors signal validity provided eye-trackers. absent, signals valid assumed.","code":""},{"path":"/reference/consolidate_signal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"","code":"consolidate_signal(   s1,   s2,   v1,   v2,   strategy = c(\"conservative\", \"liberal\", \"pick_best\"),   plausible = NULL )"},{"path":"/reference/consolidate_signal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"s1 vector first signal. s2 vector second signal. v1 vector weights first signal. v2 vector weights second signal. strategy strategy mixing two signals. Conservative takes mean signals valid. Liberal additionally take one valid signal even valid. Pick_best chooses best overall signal (valid often) disregard one two valid. plausible vector length 2 defining range plausible values pupil size. provided, values outside range set NA.","code":""},{"path":"/reference/consolidate_signal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"numeric vector consolidated pupil size NAs available.","code":""},{"path":"/reference/copy_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"Sometimes info relevant eye-tracking file found associated behavioral file. data.frames different dimensions, thus copying one variable another can cumbersome. function job expanding relevant information accordingly exploits constraints two files. task performed ID separately requires \"Trial\" variable used calculate amount required expansion data.","code":""},{"path":"/reference/copy_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"","code":"copy_variable(   var_name,   id_var = \"p_ID\",   constrained_var = \"Trial\",   larger_df = ET,   smaller_df = BD )"},{"path":"/reference/copy_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"var_name string suggesting variable look smaller data.frame (usually behavioral one) copy larger data.frame (usually eye-tracker one). id_var name ID variable grouping variable assignment must separated (e.g., performed participant). Can NULL grouping. constrained_var name variable represents available costraint. example, can Trial number 'var_name' expanded value value Trial number. larger_df larger data.frame. output vector match number rows dataframe. Typically, eye-tracker dataframe. smaller_df smaller dataframe includes 'var_name'.","code":""},{"path":"/reference/copy_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"vector 'length= nrow(larger_df)'.","code":""},{"path":"/reference/decode_signal.html","id":null,"dir":"Reference","previous_headings":"","what":"Highlights and test the time-course of effects through crossvalidation — decode_signal","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"function meant implement, roughly assurance full compatibility procedure proposed Mathôt Vilotijević (2022, Behavior Research Methods). First, trial (.e., one complete time series) assigned one fold deterministic fashion (first trial first fold, second trial second fold, etc.). , regard conditions distributed across folds, .e. data may slightly unbalanced; thus, think carefully whether strategy applies design (e.g., blocked conditions). , data separated time-point, LMEM specified 'formula' parameter, passed 'lmerTest::lmer', performed iteratively leaving one fold . results table, many rows effects implied formula 'nfolds', summarising time point peak t-value (absolute value) trained folds. separate table peak values tested: dependent variable becomes, fold, variable provided 'dv' specific peak. Another LMEM computed using newly created variable. One problem approach peak values can places, depending data. Also, choosing time-points based maximum value training dataset can occasionally decrease precision estimate give overfitting. may use approach confident specific effect effect specific window; effects multiple windows - e.g., early late impact pupil size - may properly captured approach. Therefore, addition procedure, coarse consensus seek assessing, across folds effects, time points resulted t-values certain threshold; time points pop consistently across folds (e.g.,= 'consensus_thresh' % times), time point retained; time-pointsretained consensus collapsed (averaged), final LMEM performed withthese time points. can interpreted similarly cluster-basedpermutation test (although ).","code":""},{"path":"/reference/decode_signal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"","code":"decode_signal(   data,   formula,   dv,   time,   id,   trial,   nfolds = 3,   t_thresh = 2,   consensus_thresh = 0.75,   formula_max = NULL )"},{"path":"/reference/decode_signal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"data data.frame containing necessary variables. formula 'lme4'-style formula, passed string. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. nfolds Number folds split trials . Defaults 3. t_thresh Used seek consensus: minimum t-value required push time-point forward. consensus_thresh minimum proportion time-points must 't_thresh' across folds order keep time-point consensus. formula_max 'lme4'-style formula, passed string. formula used test final models. useful save computational resources. necessarily recommend overly conservative prone convergence issues.","code":""},{"path":"/reference/decode_signal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"list including: peaks retained (left-) fold; test retained, cross-validated peaks; test consensus time-points, ; list time-points retained consensus effect.","code":""},{"path":"/reference/decode_signal_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"'decode_signal()' except powered 'glmer()' thus performs generalized LMEMs.","code":""},{"path":"/reference/decode_signal_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"","code":"decode_signal_g(   data,   formula,   dv,   time,   id,   trial,   nfolds = 3,   t_thresh = 2,   consensus_thresh = 0.75,   ... )"},{"path":"/reference/decode_signal_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"data data.frame containing necessary variables. formula 'lme4'-style formula, passed string. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. nfolds Number folds split trials . Defaults 3. t_thresh Used seek consensus: minimum t-value required push time-point forward. consensus_thresh minimum proportion time-points must 't_thresh' across folds order keep time-point consensus. ... params 'glmer()', e.g. \"family\".","code":""},{"path":"/reference/decode_signal_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"list including: peaks retained (left-) fold; test retained, cross-validated peaks; test consensus time-points, ; list time-points retained consensus effect.","code":""},{"path":"/reference/detect_change.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect a change in a column, and returns an incremental counter — detect_change","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"Mostly used, e.g., case ET file provide Trial number column. function monitors occurrences 'key' value , value appears first time, increases counter 1. example, return counter first occurrences \"target\" \"Event\" column, thus returning putative trial number assuming target repeated iteration. default, column track filled downward. Also, empty lines changed NA. final remark, may need clean lines assigned trial (sometimes, e.g., eyetracker needs time warm ).","code":""},{"path":"/reference/detect_change.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"","code":"detect_change(vector, key)"},{"path":"/reference/detect_change.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"vector vector variable tracked. key Value track, first repetition update counter.","code":""},{"path":"/reference/detect_change.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"numeric vector returning counter - function can thus used tidyverse-style pipelines grouping (e.g., ID).","code":""},{"path":"/reference/downsample_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode a Time variable to a different granularity — downsample_time","title":"Recode a Time variable to a different granularity — downsample_time","text":"time variable passed function corresponding downsampled time bin returned. One 'to_ms' 'to_hz' must null","code":""},{"path":"/reference/downsample_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode a Time variable to a different granularity — downsample_time","text":"","code":"downsample_time(Time, to_ms = 25, to_hz = NULL)"},{"path":"/reference/downsample_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode a Time variable to a different granularity — downsample_time","text":"Time vector variable indicating elapsed time, ms, aligned origin - .e., timestamp. to_ms many ms bins must . to_hz many hertz new sampling rate .","code":""},{"path":"/reference/downsample_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode a Time variable to a different granularity — downsample_time","text":"numeric time vector recoded time bins.","code":""},{"path":"/reference/interpolate.html","id":null,"dir":"Reference","previous_headings":"","what":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"used linearly interpolate data provided successful quality controls. controls met, returned vector vector equal length composed NAs. Quality checks general (.e., overall percentage available non NA data) relative consecutive gaps signal, must exceed given threshold. Thresholds refer maximum rate (percentage) entries allowed NAs; results interpolated thresholds.","code":""},{"path":"/reference/interpolate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"","code":"interpolate(   vector,   extend_blink = pp_options(\"extend_blink\"),   overall_thresh = pp_options(\"overall_thresh\"),   consecutive_thresh = pp_options(\"consecutive_thresh\") )"},{"path":"/reference/interpolate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"vector vector interpolate. extend_blink NAs extended many samples prior interpolation. gets rid signal may compromised close proximity blink. overall_thresh Overall quality threshold: e.g., total amount data allowed missing original vector. consecutive_thresh Consecutive gaps signal: e.g., total amount data allowed missing original vector consecutively.","code":""},{"path":"/reference/interpolate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"numeric vector interpolated data NAs quality checks met.","code":""},{"path":"/reference/plot_fingerprints.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot all (three) fingerprints of reduced time-series — plot_fingerprints","title":"Plot all (three) fingerprints of reduced time-series — plot_fingerprints","text":"function active development. meant depict three eigenvectors/loadings/weights components obtained reducing pupillary time-series, ease interpretation. Note components names re-ordered according explained variance default, names, results may differ original scores. mindful!","code":""},{"path":"/reference/plot_fingerprints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot all (three) fingerprints of reduced time-series — plot_fingerprints","text":"","code":"plot_fingerprints(data, order = \"var\", flip = c(1, 1, 1))"},{"path":"/reference/plot_fingerprints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot all (three) fingerprints of reduced time-series — plot_fingerprints","text":"data object returned , e.g., 'reduce_PCA'. order character, defaults \"var\" reordering fingerprints share explained variance. Else \"none\" \"peak\", order latency peak value. flip vector numbers indicating component(s) flip sign (e.g., c(1,1,-1))","code":""},{"path":"/reference/plot_fingerprints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot all (three) fingerprints of reduced time-series — plot_fingerprints","text":"plot powered 'ggplot2'.","code":""},{"path":"/reference/plot_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot loadings of a reduced time-series — plot_loadings","title":"Plot loadings of a reduced time-series — plot_loadings","text":"function active development. meant depict loadings components obtained reducing pupillary time-series, ease interpretation.","code":""},{"path":"/reference/plot_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot loadings of a reduced time-series — plot_loadings","text":"","code":"plot_loadings(name, data)"},{"path":"/reference/plot_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot loadings of a reduced time-series — plot_loadings","text":"name string indicating component depict (e.g., \"PC1\"). data object returned , e.g., 'reduce_PCA'.","code":""},{"path":"/reference/plot_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot loadings of a reduced time-series — plot_loadings","text":"plot powered 'ggplot2'.","code":""},{"path":"/reference/plot_manifold.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a 3D scatterplot (based on plot3D) based on a reduce_rPCA object — plot_manifold","title":"Plot a 3D scatterplot (based on plot3D) based on a reduce_rPCA object — plot_manifold","text":"function active development. meant depict three scores components obtained reducing pupillary time-series rPCA. strong assumptions, first foremost object rotated PCA, includes variables named \"RC1\" - x axis, \"RC2\" - y axis, \"RC3\" - z axis. function wrapper around 'plot3D::scatter3D' thus package required.","code":""},{"path":"/reference/plot_manifold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a 3D scatterplot (based on plot3D) based on a reduce_rPCA object — plot_manifold","text":"","code":"plot_manifold(   Scores,   colvar = NULL,   col = NULL,   theta = 0,   phi = 0,   pch = 16,   cex = 2,   adapt3D = F,   xlim = NULL,   ylim = NULL,   zlim = NULL )"},{"path":"/reference/plot_manifold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a 3D scatterplot (based on plot3D) based on a reduce_rPCA object — plot_manifold","text":"Scores object returned 'reduce_rPCA'. adapt3D Whether axis \"\", FALSE, strectched fit 3D box, TRUE colvar;col name variable use colors; char vectors colors. theta;phi angles \"eyes\" plot pch;cex graphical pars defining shape size points plotted xlim;ylim;zlim manually supply limits","code":""},{"path":"/reference/plot_manifold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a 3D scatterplot (based on plot3D) based on a reduce_rPCA object — plot_manifold","text":"3D plot powered 'plot3D'.","code":""},{"path":"/reference/pp_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set or get options for Pupilla's preprocessing parameters — pp_options","title":"Set or get options for Pupilla's preprocessing parameters — pp_options","text":"Set get options Pupilla's preprocessing parameters","code":""},{"path":"/reference/pp_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set or get options for Pupilla's preprocessing parameters — pp_options","text":"","code":"pp_options(...)"},{"path":"/reference/pp_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set or get options for Pupilla's preprocessing parameters — pp_options","text":"thresh speed_clean Threshold (z point absolute value) values marked NA. speed_method speed_clean Whether 'thresh' z-score ('z'), deviant values omitted , values threshold ('z-dynamic'). 'abs' used instead precise absolute value speed supplied. extend_by speed_clean Number samples starting deviant speed values stripped (e.g., signal proximity blinks may biased well). island_size speed_clean Islands signal midst NAs removed smaller equal threshold (amount samples). extend_blink interpolate NAs extended many samples prior interpolation. gets rid signal may compromised close proximity blink. overall_thresh interpolate Overall quality threshold: e.g., total amount data allowed missing original vector. consecutive_thresh interpolate Consecutive gaps signal: e.g., total amount data allowed missing original vector consecutively. disable_smoothing smooth Whether want disable smoothing. parameter FALSE default; want disable smoothing, set TRUE. spar smooth Smoothing factor 'smooth.spline()'.","code":""},{"path":"/reference/pre_process.html","id":null,"dir":"Reference","previous_headings":"","what":"A convenience function to preprocess pupillometry data — pre_process","title":"A convenience function to preprocess pupillometry data — pre_process","text":"function calls, order, 'speed_clean', 'interpolate', 'smooth_vector' packages. Parameters can changed package options, .e. 'Pupilla::pp_options()'. Warning, best preprocessing parameters may deviate defaults used , mindful!","code":""},{"path":"/reference/pre_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A convenience function to preprocess pupillometry data — pre_process","text":"","code":"pre_process(vector, time)"},{"path":"/reference/pre_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A convenience function to preprocess pupillometry data — pre_process","text":"vector vector variable cleaned time vector variable indicating elapsed time, needed compute velocity.","code":""},{"path":"/reference/pre_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A convenience function to preprocess pupillometry data — pre_process","text":"numeric vector processed requested per default. .","code":""},{"path":"/reference/predict_feature.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicts features' scores from a model — predict_feature","title":"Predicts features' scores from a model — predict_feature","text":"development. function meant predict scores features obtained trained model one returned 'reduce_*' family functions. particular, function ideally work technique implemented far (PCA, rPCA, ICA) whether scaling centering required. function used within stringent crossclassification approach (scores computed) anew, even different tasks check whether different signatures can observed independent pool data. takes input \"time\" argument ensure timepoints used model compute loadings match, function returns error.","code":""},{"path":"/reference/predict_feature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicts features' scores from a model — predict_feature","text":"","code":"predict_feature(vector, time, model, use_trimmed = FALSE)"},{"path":"/reference/predict_feature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicts features' scores from a model — predict_feature","text":"vector vector variable transformed according given model. Usually pupil dimension trial/condition. time vector variable indicating elapsed time. loadings' names model model Object returned 'reduce_*', e.g. 'reduce_PCA()'. use_trimmed Defaults FALSE. However, rPCA loadings previously trimmed 'trim_loadings' (corresponding values appended model provided), predictions made trimmed loadings. works rPCA.","code":""},{"path":"/reference/predict_feature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicts features' scores from a model — predict_feature","text":"dataframe scores - many loadings model.","code":""},{"path":"/reference/read_TOBII.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"two type data usually separate sometimes must merged create one single file eyetracking experimental details (e.g., conditions), unless specified via code experiment builder. function written OpenSesame-like csv files mind, though compatibility programs (e.g., e-prime) may achieved provided files converted csv format. optimized Windows machines - may encounter address errors Macs.","code":""},{"path":"/reference/read_TOBII.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"","code":"read_TOBII(   ID,   path = getwd(),   start_filename = \"subject-\",   append_TOBII = \"_TOBII_output.tsv\",   skip = 7,   separate_behavioral = TRUE )"},{"path":"/reference/read_TOBII.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"ID integer corresponding one participant's ID. attached current path order locate two files read. Also, One variable named p_ID attached ET BD files. vector supplied, files read lapply merged. path Defaults getwd() can specified otherwise. Files searched starting location. start_filename string, defaults \"subject-\". Usually files start string, regardless nature. Usually names built concatenating path, start_filename, ID, append_TOBII (eye-tracking data, else \".csv\"). append_TOBII string, defaults \"_TOBII_output.tsv\" indicates text tells eye-tracking behavioral files apart. Usually names built concatenating path, start_filename, ID, append_TOBII (eye-tracking data, else \".csv\"). skip Integer. amount lines skip eye-tracking file, .e. many lines header encountered. passed data.table::fread(). separate_behavioral defaults TRUE. FALSE, reads eye-tracking data","code":""},{"path":"/reference/read_TOBII.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"list one two DFs, one eye-tracking data, one behavioral data (requested).","code":""},{"path":"/reference/read_eyelink.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"two type data usually separate sometimes must merged create one single file eyetracking experimental details (e.g., conditions), unless specified via code experiment builder. function written OpenSesame-like csv files mind, though compatibility programs (e.g., e-prime) may achieved provided files converted csv format. optimized Windows machines - may encounter address errors Macs.","code":""},{"path":"/reference/read_eyelink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"","code":"read_eyelink(   ID,   keep_events = NULL,   path = getwd(),   start_behavior = \"subject-\",   start_eyelink = \"sub_\",   separate_behavioral = TRUE,   import_all = T )"},{"path":"/reference/read_eyelink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"ID integer corresponding one participant's ID. attached current path order locate two files read. Also, One variable named p_ID attached ET BD files. vector supplied, files read lapply merged. keep_events character vector specifying events kept. hard assumption experimental phases recorded messages events$messages slot returned 'eyelinkReader::read_edf()'. path Defaults getwd() can specified otherwise. Files searched starting location. start_behavior string, defaults \"subject-\". Usually files start string, regardless nature. Usually names built concatenating path, start_filename, ID, .csv. start_eyelink string, defaults \"subject-\". Usually files start string, regardless nature. Usually names built concatenating path, start_eyelink, ID, .edf. separate_behavioral defaults TRUE. FALSE, reads eye-tracking data import_all TRUE (default) import blink fixation data computed eyelink.","code":""},{"path":"/reference/read_eyelink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"list one two DFs, one eye-tracking data, one behavioral data (requested).","code":""},{"path":"/reference/read_eyelink.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"function wrapper around 'eyelinkReader::read_edf()' must installed. order use package, eyelink proprietary code must installed well (relevant scripts available eyelink forum)","code":""},{"path":"/reference/reduce_ICA.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce time-series to few Independent Components — reduce_ICA","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"function active development. meant reduce entire time-series normalized baseline-corrected pupillary data just scores obtained Independent Component Analysis. ICA effective way reduce data dimensionality manageable dependent variables, may additionally help precise estimates (fingerprints) pupil signal underlying cognitive processes. functions use 'ica::icafast'.","code":""},{"path":"/reference/reduce_ICA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"","code":"reduce_ICA(   data,   dv,   time,   id,   trial,   Ncomp = NULL,   center = FALSE,   scale = FALSE,   add )"},{"path":"/reference/reduce_ICA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"data data.frame containing necessary variables. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. Ncomp Number components retain. default (NULL) automatically retains 95% explained variance. Ncomp== \"\" returns components. Ncomp <1 interpreted user wishes retain given proportion variance (e.g. 0.6). center Whether variables, .e. pupil size timepoint, centered beforehand. Defaults FALSE assuming measures already baseline-corrected. scale Whether variables, .e. pupil size timepoint, centered beforehand. Defaults FALSE assuming measures already baseline-corrected. add String(s) indicating variables names, , appendend scores dataframe.","code":""},{"path":"/reference/reduce_ICA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"list including processed data, scores loadings dataframes, ICA object useful prediction new data.","code":""},{"path":"/reference/reduce_PCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce time-series to few Principal Components — reduce_PCA","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"function active development. meant reduce entire time-series normalized baseline-corrected pupillary data just scores obtained Principal Component Analysis. PCA effective way reduce data dimensionality manageable dependent variables, may additionally help precise estimates (fingerprints) pupil signal underlying cognitive processes.","code":""},{"path":"/reference/reduce_PCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"","code":"reduce_PCA(   data,   dv,   time,   id,   trial,   Ncomp = NULL,   center = FALSE,   scale = FALSE,   add )"},{"path":"/reference/reduce_PCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"data data.frame containing necessary variables. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. Ncomp Number components retain. default (NULL) automatically retains 95% explained variance. Ncomp== \"\" returns components. Ncomp <1 interpreted user wishes retain given proportion variance (e.g. 0.6). center Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. scale Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. add String(s) indicating variables names, , appendend scores dataframe.","code":""},{"path":"/reference/reduce_PCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"list including processed data, scores loadings dataframes, PCA object useful prediction new data.","code":""},{"path":"/reference/reduce_rPCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"function active development. meant reduce entire time-series normalized baseline-corrected pupillary data just scores obtained rotated Principal Component Analysis. PCA effective way reduce data dimensionality manageable dependent variables, may additionally help precise estimates (fingerprints) pupil signal underlying cognitive processes. Rotation oblique sense force PCs orthogonal may help interpretation resulting loadings. function uses 'psych::principal()' may differ standardization performed.","code":""},{"path":"/reference/reduce_rPCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"","code":"reduce_rPCA(   data,   dv,   time,   id,   trial,   Ncomp = NULL,   center = FALSE,   scale = FALSE,   rotate = \"promax\",   add )"},{"path":"/reference/reduce_rPCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"data data.frame containing necessary variables. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. Ncomp Number components retain. default (NULL) automatically retains 95% explained variance. Note , however, based unrotated PCA, rotated variables generally explain less variance. Ncomp== \"\" returns components. Ncomp <1 interpreted user wishes retain given proportion variance (e.g. 0.6), unrotated PCA used find number components. center Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. Note impacts summaryPCA number components retained psych uses covariance matrix. scale Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. Note impacts summaryPCA number components retained psych uses covariance matrix. rotate Defaults \"promax\" oblique rotation. set \"none\" PCA style 'psych' package. Accepts accepted 'psych::principal()'. add String(s) indicating variables names, , appendend scores dataframe.","code":""},{"path":"/reference/reduce_rPCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"list including processed data, scores loadings dataframes, PCA object useful prediction new data.","code":""},{"path":"/reference/smooth_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth a time series through cubic splines — smooth_vector","title":"Smooth a time series through cubic splines — smooth_vector","text":"can used simple smoothing function, case eyetracking data can used low-pass filter, useful correct artifacts, blinks, etc.","code":""},{"path":"/reference/smooth_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth a time series through cubic splines — smooth_vector","text":"","code":"smooth_vector(   vector,   time,   spar = pp_options(\"spar\"),   disable_smoothing = pp_options(\"disable_smoothing\") )"},{"path":"/reference/smooth_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth a time series through cubic splines — smooth_vector","text":"vector vector variable smoothed. time vector variable indicating elapsed time. spar Smoothing factor 'smooth.spline()'. disable_smoothing Whether want disable smoothing. parameter FALSE default; want disable smoothing, set TRUE.","code":""},{"path":"/reference/smooth_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth a time series through cubic splines — smooth_vector","text":"numeric vector smoothed requested.","code":""},{"path":"/reference/speed_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Help identifying artifacts with a speed-based criterion — speed_clean","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"signal vector stripped values exceeding given threshold, computed basis absolute speed signal increase decrease.","code":""},{"path":"/reference/speed_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"","code":"speed_clean(   vector,   time,   thresh = pp_options(\"thresh\"),   speed_method = pp_options(\"speed_method\"),   extend_by = pp_options(\"extend_by\"),   island_size = pp_options(\"island_size\") )"},{"path":"/reference/speed_clean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"vector vector variable cleaned time vector variable indicating elapsed time, needed compute velocity. thresh Threshold (z point absolute value) values marked NA. speed_method Whether 'thresh' z-score ('z'), deviant values omitted , values threshold ('z-dynamic'). 'abs' used instead precise absolute value speed supplied. extend_by Number samples starting deviant speed values stripped (e.g., signal proximity blinks may biased well). island_size Islands signal midst NAs removed smaller equal threshold (amount samples).","code":""},{"path":"/reference/speed_clean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"numeric vector cleaned requested.","code":""},{"path":"/reference/trim_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim rPCA loadings according to heuristics and append them to the original object — trim_loadings","title":"Trim rPCA loadings according to heuristics and append them to the original object — trim_loadings","text":"development. function takes 'reduce_rPCA' object, 'reduce_rPCA' object, trims original loadings. trimmed loadings can used (new) predictions 'predict_feature()', example. One reason useful reduce collinearity rotated components - albeit one can also consider orthogonal solutions.","code":""},{"path":"/reference/trim_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim rPCA loadings according to heuristics and append them to the original object — trim_loadings","text":"","code":"trim_loadings(rpca_mod, keep_max = T, abs_value = 0.4)"},{"path":"/reference/trim_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim rPCA loadings according to heuristics and append them to the original object — trim_loadings","text":"rpca_mod object returned 'reduce_rPCA'. keep_max TRUE, timepoint largest loading (absolute value) preserved, remaining ones set 0. abs_value absolute value loadings set 0","code":""},{"path":"/reference/trim_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trim rPCA loadings according to heuristics and append them to the original object — trim_loadings","text":"original object information trimming added","code":""}]

[{"path":"/articles/Pupilla.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Pupilla","text":"package currently available GitHub. installation requires R package devtools.","code":"# install.packages(\"devtools\") devtools::install_github(\"EBlini/Pupilla\")"},{"path":"/articles/Pupilla.html","id":"scope","dir":"Articles","previous_headings":"","what":"Scope","title":"Pupilla","text":"collection functions wrappers useful preprocessing analyze eyetracking data, special focus pupillometry. functions designed data TOBII’s eyetrackers collected third-part experiment builders OpenSesame. functions considered development: requests suggestions welcome, :) . useful references, example results functions, see Blini Zorzi, 2023.","code":""},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Pupilla::Advanced statistical analyses","text":"Pupilla gathers several functions designed facilitate analysis pupillometry experiments commonly performed cognitive neuroscience, e.g. event-related designs, although use much general. vignette cover statistical modelling step. Pupilla provides functions implement two approaches: Crossvalidated LMEMs Mathôt & Vilotijević, 2022. original - thus yet fully validated scientific articles - approach feature reduction. use data Zhou et al., 2022 better comparison - indeed differences implementation LMEMs R Python, top course specific choices ’ve made within package. grateful authors sharing data allowing us reproducible, exploitable science.","code":""},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"prepping-the-data","dir":"Articles","previous_headings":"","what":"Prepping the data","title":"Pupilla::Advanced statistical analyses","text":"need following R packages: python interface: Note package reticulate requires python environment installation required modules. package needed read .pkl files directly within R, original format data. Accordingly, following chunk run python engine - , need include within reticulate repl using markdown. use read original data, convert pandas dataframe, move R environment. python environment available R py. can thus manipulate data usual functions. particular, variable pupil read array, whereas prefer long dataframe R. thus reshape bit data follows - based understanding structure: add explicit “Trial” variable data. variable “Set_Size” also converted factor. NA data. generally problematic LMEMs, can handle well slightly unbalanced designs, values well omitted. slightly problematic second approach, features reduction, missing values may lead loss entire trial. approach, sort interpolation warranted , course, gaps large. vignette simply interpolate missing values linearly zoo::na.approx(). Note function work NAs located beginning end vector, won’t get rid NAs. plot average pupil size Set_Size Color_type. plot looks quite like original one, sould far original data.  really depicting variability. However, matters : 1) large effect Set_Size; 2) may (well, know paper , :) ) interaction Set_Size Color_type effect non-prototypical color reversed 1 4. Let’s analyze data!","code":"library(\"dplyr\") ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(\"Pupilla\") library(\"ggplot2\") library(\"emmeans\") library(\"lmerTest\") ## Loading required package: lme4 ## Loading required package: Matrix ##  ## Attaching package: 'lmerTest' ## The following object is masked from 'package:lme4': ##  ##     lmer ## The following object is masked from 'package:stats': ##  ##     step library(\"zoo\") ##  ## Attaching package: 'zoo' ## The following objects are masked from 'package:base': ##  ##     as.Date, as.Date.numeric options(dplyr.summarise.inform = FALSE) library(\"reticulate\")  # #create python environment #conda_create(\"my_env\") #use_miniconda(\"my_env\")  # #install packages in the environment # py_install(\"pandas\") # py_install(\"datamatrix\") from datamatrix import io, convert  address= \"data\\\\zhou_et_al_2021.pkl\"  data= io.readpickle(address)  data= convert.to_pandas(data)  quit DF= py$data #bring to R  DF2 = lapply(1:nrow(DF), function(x) {   res = data.frame(     Pupil = as.vector(DF$pupil[[x]]),     Set_size = DF$set_size[x],     Subject = DF$subject_nr[x],     Color_type = DF$color_type[x],     Time = seq(0, 3, length = 300)   )      return(res)    })  DF2= do.call(rbind, DF2) DF2= DF2 %>%    group_by(Subject, Time) %>%    mutate(Trial= 1:n())  DF2= data.frame(DF2)  DF2$Set_size= as.factor(DF2$Set_size) sum(is.na(DF2$Pupil)) ## [1] 35786 DF2= DF2 %>%    group_by(Subject, Trial) %>%    mutate(Pupil= zoo::na.approx(Pupil, na.rm = F))  sum(is.na(DF2$Pupil)) ## [1] 2009 DF2 %>%    group_by(Subject, Time, Color_type, Set_size) %>%    summarise(Pupil= mean(Pupil, na.rm= T)) %>%   group_by(Time, Color_type, Set_size) %>%    summarise(Pupil= mean(Pupil)) %>%   mutate(Set_size= as.factor(Set_size)) %>%    ggplot(aes(y= Pupil, x= Time,               color= Set_size,               linetype= Color_type,              group = interaction(Set_size, Color_type))) +   geom_line(linewidth= 1.2) +   theme(text= element_text(size= 16,                            face=\"bold\")) +   xlab(\"Time (s)\") +   ylab(\"Pupil size (a.u.)\") +   ggtitle(\"Data from: Zhou, Lorist, and Mathôt (2022)\")"},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"crossvalidated-lmems","dir":"Articles","previous_headings":"","what":"Crossvalidated LMEMs","title":"Pupilla::Advanced statistical analyses","text":"approach Mathôt & Vilotijević, 2022, trials participant assigned deterministically one N folds. N-1 folds circularly used training set; , LMEMs performed timepoint, timepoint peak t-value (fixed effect interaction) used test set confirm overall consistency target effect across folds. approach computationally efficient powerful suggesting presence consistent experimental effect somewhere along time course trials. Pupilla. ’s ! first take look global effects, LMEMs tested relative peaks: First, may notice results taken lmerTest::lmer() reflect default contrast settings R, treatment coding. words, case factors first level taken reference. case ’s pretty clear us aim compare Set_size 1 vs 4; want compare explicity contrasts, refactor variables. understanding packages may perform “omnibus tests”; R feasible, e.g. car::Anova(), perhaps implemented feature. interpretation , however, omnibus test (e.g., main effect ANOVA), specific comparisons. also notice main inferential statistic t value, rather z F value. said, results positive Set_size (differs 1) interaction Color_type Set_size 1 4. therefore taken evidence presence effect somewhere along time course trials. following table reports statistics fold, fold left . useful understand peaks located. First, comparisons Set_size 1 vs 2 3 similar locating peaks around 1 second. Results slightly sparse 1 vs 4 comparison (1 2.8 s). find main effect Color_type . due contrasts used, differences trials assigned folds, presence possible convergence failures, etc. see, example, t values main effect Color_type positive two folds, negative one. due, , funny convergence, simply fact overfitting occurrred one specific time point (sample 5). introduce notion consensus across folds. Finally, interaction also seemingly consistent 1.4 1.7 seconds. Overall, seems good agreement original findings, notwithstanding differences implementation. , however, couple caveats, also mentioned authors. First, temporal information provided approach rather coarse. can test presence effect somewhere along course trial, though specific timepoints may rather vague. Second, presence two distinct loci effects, approach entirely appropriate, especially direction effects opposite direction. Finally, tested time point chosen one peak statistic (e.g., t value), approach may prone overfitting; time points may , fact, representative effects hand.","code":"#the data data= DF2 #lme4::lmer-style formula  #here we use only random intercepts formula= \"Pupil ~ Set_size*Color_type + (1|Subject)\" #you also have to supply explicitly the names of the variables dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" #how many folds? nfolds= 3 #used for the consensus across folds - see below t_thresh= 1.9 consensus_thresh = 0.99  cv= decode_signal(data= DF2,                    formula= formula,                   dv= dv,                   time= time,                   id= id,                   trial= trial,                   nfolds= nfolds,                   t_thresh= t_thresh,                   consensus_thresh= consensus_thresh) ## boundary (singular) fit: see help('isSingular') ## boundary (singular) fit: see help('isSingular') cv$Peaks_test ##                      Effect      Test_t    Test_df       Test_p ## 1               (Intercept) -12.0345532   31.90004 2.127767e-13 ## 2                 Set_size2   7.4219908 7276.01675 1.284641e-13 ## 3                 Set_size3  14.4253720 7276.01727 1.564918e-46 ## 4                 Set_size4  12.6268559 7263.07280 3.595688e-36 ## 5           Color_typeproto  -1.5116082 7269.07742 1.306770e-01 ## 6 Set_size2:Color_typeproto   0.8674076 7270.09839 3.857473e-01 ## 7 Set_size3:Color_typeproto   1.0893240 7273.07358 2.760471e-01 ## 8 Set_size4:Color_typeproto   2.4009727 7273.04856 1.637651e-02 cv$All_Folds ##    Fold                    Effect     Peak_t Peak_obs  Peak_time ## 1     1               (Intercept) -12.141355       89 0.88294314 ## 2     2               (Intercept) -11.509067       87 0.86287625 ## 3     3               (Intercept) -12.037152       89 0.88294314 ## 4     1                 Set_size2   6.233502       95 0.94314381 ## 5     2                 Set_size2   5.663626       89 0.88294314 ## 6     3                 Set_size2   7.076464       97 0.96321070 ## 7     1                 Set_size3  12.371973       98 0.97324415 ## 8     2                 Set_size3  11.366762       98 0.97324415 ## 9     3                 Set_size3  11.770977       97 0.96321070 ## 10    1                 Set_size4  13.232442      103 1.02341137 ## 11    2                 Set_size4  12.609223      282 2.81939799 ## 12    3                 Set_size4  13.366514      221 2.20735786 ## 13    1           Color_typeproto  -2.484261      167 1.66555184 ## 14    2           Color_typeproto  -2.121288      159 1.58528428 ## 15    3           Color_typeproto   1.807755        5 0.04013378 ## 16    1 Set_size2:Color_typeproto   2.398834      165 1.64548495 ## 17    2 Set_size2:Color_typeproto   2.987624      156 1.55518395 ## 18    3 Set_size2:Color_typeproto  -1.623268        7 0.06020067 ## 19    1 Set_size3:Color_typeproto   1.707470      158 1.57525084 ## 20    2 Set_size3:Color_typeproto   2.071359      146 1.45484950 ## 21    3 Set_size3:Color_typeproto  -2.007344        8 0.07023411 ## 22    1 Set_size4:Color_typeproto   3.216884      171 1.70568562 ## 23    2 Set_size4:Color_typeproto   2.794211      159 1.58528428 ## 24    3 Set_size4:Color_typeproto   1.950378      142 1.41471572"},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"consensus","dir":"Articles","previous_headings":"Crossvalidated LMEMs","what":"Consensus","title":"Pupilla::Advanced statistical analyses","text":"common problem, machine learning, find consensus hyperparameters obtained different folds. Particularly need build one final model interpret results (see, e.g., package FCnet analysis neuroimaging data elastic nets). Long story short, one possible solution put forward Pupilla quite simple, though arbitrary: simply keep track timepoints associated given threshold, e.g. t statistic 1.9 case, consider agreement across folds … time points show consistently across folds! ’s simple . specific example ask folds agreement (>99%), meaning timepoints must remain significant regardless fold left data. (ensure none folds particular leverage driving overal results). effects specified, consensus across folds? Yes! consensus clear contrast within Set_size interaction Color_type (1 vs 4), latter case sample 136 147. can formally test consensus window another LMEM: , , presence effect confirmed. summarise, approach advantage returning precise time window given experimental effect; maintains computational efficiency crossvalidated approach; capable highlight potentially clusters contiguous. downside arbitrary choices - e.g., threshold statistic - must specified beforehand. personal take matter , researchers, start comfortable degrees freedom, unavoidable job, embrace , just resolve tranparently report choices avoid overselling stuff. get , really ingrained . Keep mind , however, conflict can resolved elegantly preregistration experimental methods. rate, long discussion vignette. Let’s introduce second approach pursued Pupilla: features reduction.","code":"cv$Consensus ## $`(Intercept)` ##   [1]  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 ##  ## $Set_size2 ##   [1]  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 178 ##  ## $Set_size3 ##   [1]  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 ## [249] 295 296 297 298 299 300 ##  ## $Set_size4 ##   [1]  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 ## [249] 297 298 299 300 ##  ## $Color_typeproto ## numeric(0) ##  ## $`Set_size2:Color_typeproto` ## numeric(0) ##  ## $`Set_size3:Color_typeproto` ## numeric(0) ##  ## $`Set_size4:Color_typeproto` ##  [1] 136 138 139 141 142 143 144 145 146 147 cv$Consensus_test ##                      Effect    Test_t    Test_df       Test_p ## 1               (Intercept) -2.447735   44.98978 0.0183421194 ## 2                 Set_size2  3.543109 7276.01207 0.0003979187 ## 3                 Set_size3  3.052632 7276.01359 0.0022766268 ## 4                 Set_size4  2.915928 7276.01471 0.0035571531 ## 5           Color_typeproto        NA         NA           NA ## 6 Set_size2:Color_typeproto        NA         NA           NA ## 7 Set_size3:Color_typeproto        NA         NA           NA ## 8 Set_size4:Color_typeproto  2.685758 7274.04215 0.0072529680"},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"feature-reduction","dir":"Articles","previous_headings":"","what":"Feature reduction","title":"Pupilla::Advanced statistical analyses","text":"live time big data. result, often necessary (empowering) reduce dimensions initial data , much manageable features preserve original variability. example Principal components analysis Independent Components Analysis rich data (e.g., neuroimaging) can reduced features, can enter multivariate analyses (see, e.g., FCnet). can done pupillometry data. fact, pupil dilation strongly autocorrelated time, approach potentially effective. Pupilla::reduce_PCA() Pupilla::reduce_ICA() attempt summarising trial scores; scores reflect contribution pupil diameter time point, weighted loadings matrix. loadings vary function importance contribution time point, thus capturing sort relevant pattern data. notation Pupilla similar used : used PCA (though ICA similar specific case). can see approach tremendously effective reducing data, 2 components can explain 90% original data! means can summarise trial describe fairly well pattern pupil dilation 2 values! Generally speaking first component captures main axis variability, ends describing best overall shape curves seen original plot . can depict :  loadings suggest first PC captures overall dilation/constriction occurring late stages trial, 1 second. (Keep mind sign loadings completely arbitrary, plot well reversed, know data probably refers dilation.) , following components gruadually capture remaining variability, e.g.:  Meaning go , likely capture idiosincratic (small) trial-wise changes. really case second component (24% variance explained), captures well likely initial response, e.g. pupillary light reflex. note interpretation: PCA descriptive model, imply underlying, originating process. interpretation part completely experimenter. case, however, inferential technique. uses, shape loadings plot likely highlight segregated, least partially independent processes. move forward assessing, thus, obtained scores. Scores can , course, summarised per subject perform classic ANOVAs, used within LMEMs. choose second approach now, though still summarise data depiction purposes.","code":"#the data data= DF2 #variables names should be supplied explicitly  dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" #append to the reduced dataframe add= c(\"Set_size\", \"Color_type\")  rf = reduce_PCA(   data = DF2,   dv = dv,   time = time,   id = id,   trial = trial,   add = add ) ## Warning in reduce_PCA(data = DF2, dv = dv, time = time, id = id, trial = trial, : NAs in the data will be discarded: ##             check the data! rf$summaryPCA[,1:4] ##                               PC1        PC2       PC3       PC4 ## Standard deviation     3229.38700 1941.74683 722.69764 489.68396 ## Proportion of Variance    0.67641    0.24454   0.03388   0.01555 ## Cumulative Proportion     0.67641    0.92096   0.95483   0.97039 plot_loadings(\"PC1\", rf) plot_loadings(\"PC2\", rf) #summarise scores Scores= rf$Scores %>%    group_by(id, Set_size, Color_type) %>%    summarise(PC1= mean(PC1),             PC2= mean(PC2)) Scores$Set_size= as.factor(Scores$Set_size) rf$Scores$Set_size= as.factor(rf$Scores$Set_size)"},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"pc1","dir":"Articles","previous_headings":"Feature reduction","what":"PC1","title":"Pupilla::Advanced statistical analyses","text":"can fit LMEM model first PC: see, , large effect Set_size, interaction Color_type occurring 1 vs 4 contrast. package emmeans can avoid refactoring compute contrasts: , indeed, significant contrast. can see inversion effect prototypical / non-prototypical color two set sizes.","code":"mod_pc1= lmer(PC1 ~ Color_type*Set_size + (1|id),               rf$Scores) #note that we used the original dataframe summary(mod_pc1) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest'] ## Formula: PC1 ~ Color_type * Set_size + (1 | id) ##    Data: rf$Scores ##  ## REML criterion at convergence: 134493.4 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -4.9087 -0.6031  0.0047  0.6025  5.8052  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  id       (Intercept) 1662005  1289     ##  Residual             7524608  2743     ## Number of obs: 7202, groups:  id, 30 ##  ## Fixed effects: ##                           Estimate Std. Error       df t value Pr(>|t|)     ## (Intercept)               -1813.69     252.48    36.97  -7.184 1.62e-08 *** ## Color_typeproto            -179.27     129.73  7165.06  -1.382   0.1670     ## Set_size2                   608.64     129.25  7165.04   4.709 2.54e-06 *** ## Set_size3                  1564.30     128.97  7165.05  12.129  < 2e-16 *** ## Set_size4                  2146.06     129.19  7165.08  16.612  < 2e-16 *** ## Color_typeproto:Set_size2   241.04     183.28  7165.05   1.315   0.1885     ## Color_typeproto:Set_size3   119.03     182.78  7165.06   0.651   0.5149     ## Color_typeproto:Set_size4   398.82     183.16  7165.08   2.177   0.0295 *   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) Clr_ty St_sz2 St_sz3 St_sz4 C_:S_2 C_:S_3 ## Colr_typprt -0.255                                           ## Set_size2   -0.256  0.498                                    ## Set_size3   -0.256  0.499  0.501                             ## Set_size4   -0.256  0.498  0.500  0.501                      ## Clr_typ:S_2  0.180 -0.708 -0.705 -0.353 -0.352               ## Clr_typ:S_3  0.181 -0.710 -0.353 -0.706 -0.353  0.502        ## Clr_typ:S_4  0.180 -0.708 -0.352 -0.353 -0.705  0.501  0.503 emm_options(lmer.df = \"asymptotic\") mm= emmeans(mod_pc1, ~ Color_type:Set_size) mm ##  Color_type Set_size emmean  SE  df asymp.LCL asymp.UCL ##  nonproto   1         -1814 252 Inf     -2309     -1319 ##  proto      1         -1993 253 Inf     -2488     -1498 ##  nonproto   2         -1205 253 Inf     -1700      -710 ##  proto      2         -1143 253 Inf     -1638      -648 ##  nonproto   3          -249 252 Inf      -744       245 ##  proto      3          -310 252 Inf      -804       185 ##  nonproto   4           332 252 Inf      -162       827 ##  proto      4           552 253 Inf        57      1047 ##  ## Degrees-of-freedom method: asymptotic  ## Confidence level used: 0.95 contrast(mm, method = \"pairwise\", interaction = T) ##  Color_type_pairwise Set_size_pairwise estimate  SE  df z.ratio p.value ##  nonproto - proto    1 - 2                  241 183 Inf   1.315  0.1885 ##  nonproto - proto    1 - 3                  119 183 Inf   0.651  0.5149 ##  nonproto - proto    1 - 4                  399 183 Inf   2.177  0.0295 ##  nonproto - proto    2 - 3                 -122 183 Inf  -0.668  0.5040 ##  nonproto - proto    2 - 4                  158 183 Inf   0.862  0.3885 ##  nonproto - proto    3 - 4                  280 182 Inf   1.533  0.1252 ##  ## Degrees-of-freedom method: asymptotic ggplot(Scores, aes(y= PC1, x= Set_size, fill= Color_type)) +   geom_boxplot() +   theme(text= element_text(size= 16,                            face=\"bold\"))"},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"pc2","dir":"Articles","previous_headings":"Feature reduction","what":"PC2","title":"Pupilla::Advanced statistical analyses","text":"PC2, hand: find effect, reiterating interaction probably appears later course trial.","code":"mod_pc2= lmer(PC2 ~ Color_type*Set_size + (1|id),                rf$Scores) summary(mod_pc2) ## Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest'] ## Formula: PC2 ~ Color_type * Set_size + (1 | id) ##    Data: rf$Scores ##  ## REML criterion at convergence: 121258.8 ##  ## Scaled residuals:  ##     Min      1Q  Median      3Q     Max  ## -5.0713 -0.5643 -0.0062  0.5856  5.9442  ##  ## Random effects: ##  Groups   Name        Variance Std.Dev. ##  id       (Intercept)  473867   688.4   ##  Residual             1192655  1092.1   ## Number of obs: 7202, groups:  id, 30 ##  ## Fixed effects: ##                           Estimate Std. Error      df t value Pr(>|t|)     ## (Intercept)                1407.13     130.84   33.35  10.755 2.22e-12 *** ## Color_typeproto             -79.48      51.65 7165.03  -1.539  0.12388     ## Set_size2                  -135.53      51.46 7165.02  -2.634  0.00846 **  ## Set_size3                    58.57      51.35 7165.03   1.141  0.25401     ## Set_size4                   372.42      51.43 7165.05   7.241 4.92e-13 *** ## Color_typeproto:Set_size2   -24.67      72.97 7165.03  -0.338  0.73534     ## Color_typeproto:Set_size3    37.29      72.77 7165.04   0.512  0.60836     ## Color_typeproto:Set_size4    25.15      72.92 7165.05   0.345  0.73014     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Correlation of Fixed Effects: ##             (Intr) Clr_ty St_sz2 St_sz3 St_sz4 C_:S_2 C_:S_3 ## Colr_typprt -0.196                                           ## Set_size2   -0.196  0.498                                    ## Set_size3   -0.197  0.499  0.501                             ## Set_size4   -0.197  0.498  0.500  0.501                      ## Clr_typ:S_2  0.139 -0.708 -0.705 -0.353 -0.352               ## Clr_typ:S_3  0.139 -0.710 -0.353 -0.706 -0.353  0.502        ## Clr_typ:S_4  0.139 -0.708 -0.352 -0.353 -0.705  0.501  0.503"},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"rotated-principal-components-analysis","dir":"Articles","previous_headings":"","what":"Rotated Principal Components Analysis","title":"Pupilla::Advanced statistical analyses","text":"loadings can “rotated” : 1) interpretation easier (e.g., timepoints set closer 0, increased); 2) components orthogonal can correlate. result, model performs slightly worse terms explained variance, may allow one better, clearer interpretation loadings, may relax unrealistic assumption different components interact (correlate) significantly. implementation outlined . Please note reduce_PCA() follows prcomp(), function follows psych::principal() including standardization loadings (, even rotate \"none\" results differ slightly). ’s loadings now look:   , notwistanding differences implementation PCA - based covariance matrix psych::principal(), case second component clearly referring early part trial, presumably PLR.","code":"#the data data= DF2 #variables names should be supplied explicitly  dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" rotate= \"promax\" #oblique rotation #append to the reduced dataframe add= c(\"Set_size\", \"Color_type\")  rf2 = reduce_rPCA(   data = DF2,   dv = dv,   time = time,   id = id,   trial = trial,   rotate= rotate,   add = add ) ## Warning in reduce_rPCA(data = DF2, dv = dv, time = time, id = id, trial = trial, : NAs in the data will be discarded: ##             check the data! ## The determinant of the smoothed correlation was zero. ## This means the objective function is not defined. ## Chi square is based upon observed residuals. ## The determinant of the smoothed correlation was zero. ## This means the objective function is not defined for the null model either. ## The Chi square is thus based upon observed correlations. plot_loadings(\"RC1\", rf2) plot_loadings(\"RC2\", rf2)"},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"Pupilla::Advanced statistical analyses","text":"aim vignette present two main analytical approaches Pupilla. familiar enough domain original study adventure theoretical interpretations. Suffice say , opinion, crossvalidation approach appears replicate quite well - notwithstanding differences implementation - results reported authors. Furthermore, argument made utility consensus across folds enhance precision identifying temporal cluster. concerns second approach, .e. via feature reduction, also seen pretty coherent results. go far saying loadings PC1 can identify temporal cluster. sense, , though course dichotomic one, rather much graded, continuous one. care say , however, approach represent viable option collected data really huge, allow one obtain , much manageable variables can exploited sorts modelling purposes. Furthermore, variables may easy interpret - albeit , however, still better understand research.","code":""},{"path":"/articles/Pupilla_Advanced statistical analyses.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Pupilla::Advanced statistical analyses","text":"Packages’ versions:","code":"sessionInfo() ## R version 4.2.3 (2023-03-15 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19045) ##  ## Matrix products: default ##  ## locale: ## [1] LC_COLLATE=Italian_Italy.utf8  LC_CTYPE=Italian_Italy.utf8    LC_MONETARY=Italian_Italy.utf8 LC_NUMERIC=C                   LC_TIME=Italian_Italy.utf8     ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] zoo_1.8-12         lmerTest_3.1-3     lme4_1.1-35.1      Matrix_1.6-5       emmeans_1.10.0     ggplot2_3.4.4      Pupilla_0.0.0.9001 dplyr_1.1.4        ##  ## loaded via a namespace (and not attached): ##  [1] Rcpp_1.0.12         mvtnorm_1.2-4       lattice_0.22-5      png_0.1-8           psych_2.4.1         digest_0.6.34       utf8_1.2.4          R6_2.5.1            evaluate_0.23       coda_0.19-4.1       highr_0.10          pillar_1.9.0        rlang_1.1.3         multcomp_1.4-25     rstudioapi_0.15.0   minqa_1.2.6         jquerylib_0.1.4     nloptr_2.0.3        reticulate_1.35.0   rmarkdown_2.25      pkgdown_2.0.7       labeling_0.4.3      textshaping_0.3.7   desc_1.4.3          splines_4.2.3       stringr_1.5.1       munsell_0.5.0       numDeriv_2016.8-1.1 compiler_4.2.3      xfun_0.41           pkgconfig_2.0.3     systemfonts_1.0.5   mnormt_2.1.1        htmltools_0.5.7     tidyselect_1.2.0    tibble_3.2.1        codetools_0.2-19    fansi_1.0.6         withr_3.0.0         MASS_7.3-58.2       grid_4.2.3          nlme_3.1-162        jsonlite_1.8.8      xtable_1.8-4        gtable_0.3.4        lifecycle_1.0.4     magrittr_2.0.3      scales_1.3.0        estimability_1.4.1  ## [50] cli_3.6.2           stringi_1.8.3       cachem_1.0.8        farver_2.1.1        fs_1.6.3            bslib_0.6.1         ragg_1.2.7          generics_0.1.3      vctrs_0.6.5         boot_1.3-28.1       sandwich_3.1-0      TH.data_1.1-2       tools_4.2.3         glue_1.7.0          purrr_1.0.2         parallel_4.2.3      fastmap_1.1.1       survival_3.5-3      yaml_2.3.8          colorspace_2.1-0    memoise_2.0.1       knitr_1.45          sass_0.4.8"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Pupilla::EyeLink::Read and preprocessing","text":"Pupilla gathers several functions designed facilitate analysis pupillometry experiments commonly performed cognitive neuroscience, e.g. event-related designs, although use much general. typical analysis pipeline , coarsely, include following steps: Read data. part can vary lot depending eyetracker used, individual OS, local paths, experiment coded, etc. Pupilla provide utility functions read common eyetrackers (e.g., TOBII, EyeLink) clearly passage need tailored files. Prepare data. , part may need tailored specific needs; however, several steps common across pipelines, presented vignette. Preprocessing. Pupillometry needs robust preprocessing raw data, order reduce noise artifacts (due blinks). data properly prepared, aspect can translated across several different scenarios. course, flexibility adapting data warmly advised. Statistical modelling. Pupilla offers two approaches: 1) crossvalidated LMEMs Mathôt & Vilotijević, 2022); 2) original approach feature reduction. vignette cover analysis step. vignette focus read preprocess data single participant, tested EyeLink 1000. multiple differences may arise pipeline, according specific rationale experiment difference coding implementation. functions written OpenSesame mind. example use data Blini et al., 2023. Data can retrieved associated OSF repository. study 70 participants (following exclusions) given arithmetic task, preceded auditory cue (“easy” “hard”) prompting corresponding difficulty. response phase variable length, given auditory feedback. , trial lasted several seconds. Details provided accompanying paper, matters participants found pupillary dilation depending trial difficulty, classic result. focus data one participant. Please note pipeline default parameters Pupilla changing early development phase, results may slightly different reported elsewhere.","code":""},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"read-the-data","dir":"Articles","previous_headings":"","what":"Read the data","title":"Pupilla::EyeLink::Read and preprocessing","text":"library Pupilla must installed first, , devtools: Dependencies installed automatically. need load following packages: following steps section vary lot function software used presentation stimuli machine. Pupilla tested windows machines, may thus troubles using utility functions read participants altogether. Windows: can see: working directory set - change !; ask specific participant , vector IDs supplied; participant comes two files default OpenSesame splits eyetracker behavioral files. supplied directly character vector events - defined OpenSesame script) included relevant phases trial. datapoints belong phases kept. mandatory stage. , reading files straightforward. utility function work , however, just assume works iterating eyelinkReader::read_edf() across (eyetracking) files. order use excellent eyelinkReader package, must installed SR research-EyeLink plugins, can download forum upon registration (functions also needed control eyelink).","code":"#install.packages(\"devtools\") devtools::install_github(\"EBlini/Pupilla\") library(\"Pupilla\") library(\"dplyr\")  library(\"ggplot2\")  library(\"tidyr\")  options(dplyr.summarise.inform = FALSE) #set your own working directory first! #wd= choose.dir()  subject= 10 #vector of ids; only 1 for this example  #as coded in the program - these are the relevant eyelink messages keep_events = c(   \"fixation\",   \"cue\",   \"target1\",   \"sign\",   \"target2\",   \"calculation\",   \"response\",   \"post_resp_fix\",   \"Wait_Feedback\",   \"feedback\" )  #read  data= read_eyelink(subject, keep_events,                     path = wd)  #split for eyetracker and behavioral data ET= data$ET BD= data$BD  ET$Subject= subject BD$Subject= subject"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"prepare-the-data","dir":"Articles","previous_headings":"","what":"Prepare the data","title":"Pupilla::EyeLink::Read and preprocessing","text":"bad (?) habit record essential info eyetracker file, :) result, often variables present behavioral file (e.g., response time, condition) must copied eyetracker file, different dimensions (several lines per trial, depending sampling rate). Pupilla utility functions precisely . Specifically, behavioral data (BD) report variables Phase, Accuracy, Cue, etc. discard practice trials: experiment, recording left eye . thus set Pupil area corresponding variable: set NA Pupil values 0. mandatory preprocessing functions follow. Also, although often automatic, retain data samples fixation recorded eyelink. Next, generally remove values exceed certain threshold, e.g. < - 2.5 standard deviation subject’s mean (considering samples). can now realign timestamps first sample initial phase. , downsample 20 ms bins.","code":"#whether it's practice or experiment ET$Phase = copy_variable(   \"Phase\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) #result of the problem ET$Result = copy_variable(   \"Result\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) #response ET$Response = copy_variable(   \"response\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) #set accuracy ET$Accuracy = ifelse(ET$Response == ET$Result,                      \"correct\",                      \"incorrect\") #condition ET$Cue = copy_variable(   \"Cue\",   id_var = \"Subject\",   constrained_var = \"trial\",   larger_df = ET,   smaller_df = BD ) ET= ET[ET$Phase== \"experiment\",] BD= BD[BD$Phase== \"experiment\",] ET$Pupil= ET$paL #very important, set zeros to NA for preprocessing ET$Pupil= ifelse(ET$Pupil==0, NA, ET$Pupil)  ET$Pupil[ET$is_Fixation==0]= NA cut_off= mean(ET$Pupil, na.rm= T) - 2.5*sd(ET$Pupil, na.rm= T) ET$Pupil= ifelse(ET$Pupil < cut_off, NA, ET$Pupil) ET= ET %>%    group_by(trial) %>%    mutate(Time= time-time[Event== \"fixation\"][1])"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"preprocessing","dir":"Articles","previous_headings":"","what":"Preprocessing","title":"Pupilla::EyeLink::Read and preprocessing","text":"can finally move real thing! signal must processed impact artifacts, blinks, etc. reduced. easiest way Pupilla use pre_process() function. may want, however, consider whether specific default parameters applicable data. description parameters, see ?pp_options(). can always change default parameters calling options globally, within function . E.g.: checked defaults, preprocessing requires: ’s ! can check result pipeline visually follows:  can use function Pupilla::check_all_series() plots (, ids trials) saved images path. image, black dots represent raw, initial data. red line depicts instead reconstructed, preprocessed signal. pre_process() simply runs, order, functions deblinking (velocity-based criterion), interpolation, smoothing cubic splines. Trials data points reach given quality threshold set NA; trials can recovered , instead, recovered. , trials couldn’t restore reliable signal, simply discard ! Another common step downsampling, choose bins 20 ms: Next, personally prefer work z-scores instead arbitrary units mms, standardized measure. : particular case include response phase motor artifacts (verbal response blinks allowed), alter much pattern results. needed, can remove trials starting pupil size particularly extreme. last, crucial step baseline subtraction. analogy done paper simply realign traces median fixation phase. done! One way save preprocessed files : way group analysis faster. depict data particular participant.","code":"#the default parameters: pp_options() ## $thresh ## [1] 3 ##  ## $speed_method ## [1] \"z\" ##  ## $extend_by ## [1] 25 ##  ## $island_size ## [1] 4 ##  ## $extend_blink ## [1] 25 ##  ## $overall_thresh ## [1] 0.4 ##  ## $consecutive_thresh ## NULL ##  ## $spar ## [1] 0.8 pp_options(\"extend_by\"= 25) #strip 50 ms before and after blinks pp_options(\"extend_blink\"= 25) #further extend prior to interpolation pp_options(\"spar\"= 0.8) #smoothing parameter #entire preprocessing ET= ET %>%   group_by(Subject, trial) %>%   mutate(Pupil_pp= pre_process(Pupil, Time)) ET %>% filter(Subject==10 & trial== 13) %>%   check_series(\"Pupil\", \"Pupil_pp\", \"Time\") #drop ET= ET %>% filter(!is.na(Pupil_pp)) ET$Time= downsample_time(ET$Time, 20)  #summarise the data for the new binned variable ET= ET %>%   group_by(Subject, Cue, Event,             trial, Time, Accuracy) %>%   summarise(Pupil= median(Pupil_pp, na.rm = T)) #z scores ET$Pupil_raw= ET$Pupil  ET= ET %>%   group_by(Subject, trial) %>%   mutate(Pupil= ((Pupil - mean(Pupil[Event!= \"response\"]))/sd(Pupil[Event!= \"response\"]))) deviant_baseline= ET %>%    group_by(Subject, trial) %>%   summarise(Baseline_ps= median(Pupil[Event== \"fixation\"], na.rm=T))   deviant_baseline$Baseline_ps= scale(deviant_baseline$Baseline_ps)  #to omit omit= deviant_baseline$trial[abs(deviant_baseline$Baseline_ps)>2]  omit= na.omit(omit)  if(length(omit)>0){   ET= ET %>% filter(!trial %in% omit) } ET= ET %>%   group_by(Subject, trial) %>%   mutate(Pupil= Pupil - median(Pupil[Event== \"fixation\"])) #save preprocessed data for modelling ppdataaddress= paste0(\"pp_data//subj_\", subj, \".RDS\")     saveRDS(ET, file = ppdataaddress)"},{"path":"/articles/Pupilla_Eyelink_SingleSubjectPreprocessing.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Pupilla::EyeLink::Read and preprocessing","text":"Packages’ versions:","code":"sessionInfo()"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Pupilla_TOBII_ReduceFeatures","text":"Pupilla gathers several functions designed facilitate analysis pupillometry experiments commonly performed cognitive neuroscience, e.g. event-related designs, although use much general. typical analysis pipeline , coarsely, include following steps: Read data. part can vary lot depending eyetracker used, individual OS, local paths, experiment coded, etc. Pupilla provide utility functions read common eyetrackers (e.g., TOBII, EyeLink) clearly passage need tailored files. Prepare data. , part may need tailored specific needs; however, several steps common across pipelines, presented vignette. Preprocessing. Pupillometry needs robust preprocessing raw data, order reduce noise artifacts (due blinks). data properly prepared, aspect can translated across several different scenarios. course, flexibility adapting data warmly advised. Statistical modelling. Pupilla offers two approaches: 1) crossvalidated LMEMs Mathôt & Vilotijević, 2022); 2) original approach feature reduction. vignette covers illustrates second option. example use data Blini Zorzi, 2023. Data can retrieved associated OSF repository. eyetracker used TOBII spectrum. Unfortunately, eyetracking data acquired way quite large, meaning reading take time. study (termed Passive Viewing (PV) task) 40 participants (following exclusions), 20 smokers 20 non smokers, given, name suggests, several images look : related nicotine, neutral controls. Contrary name suggest, instead, also report (hence somehow actively) occurrence rare probe, presented screen sparingly; ensure central fixation maintained together minimum task engagement. Details provided accompanying paper, matters smokers found pupillary constriction nicotine-related images (opposed neutral ones) presented. Please note pipeline default parameters Pupilla changed since paper came PBR, results slightly different.","code":""},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"read-the-data","dir":"Articles","previous_headings":"","what":"Read the data","title":"Pupilla_TOBII_ReduceFeatures","text":"library Pupilla must installed first, , devtools: Dependencies installed automatically. need load following packages: following steps section vary lot function software used presentation stimuli machine. Pupilla tested windows machines, may thus troubles using utility functions read participants altogether. Windows: can see: working directory set - change !; 51 subjects corresponding 102 files default OpenSesame splits eyetracker behavioral files. , reading files straightforward. utility function work , however, just assume works iterating data.table::fread() across (eyetracking) files. Also, please note default first 7 lines skipped, eyetracker files may need different values!","code":"#install.packages(\"devtools\") devtools::install_github(\"EBlini/Pupilla\") library(\"Pupilla\") library(\"dplyr\")  #  # Attaching package: 'dplyr' # The following objects are masked from 'package:stats': #  #     filter, lag # The following objects are masked from 'package:base': #  #     intersect, setdiff, setequal, union library(\"ggplot2\")  library(\"tidyr\")  options(dplyr.summarise.inform = FALSE) #set your own working directory first! #wd= choose.dir()  subject= 1:51 #vector of ids #groups- whether ids are smokers or not;  #this I didn't know beforehand so I have to add manually this var group= c(\"NS\", \"S\", \"NS\", \"NS\", \"S\",\"S\", \"NS\", \"S\",          \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"NS\", \"S\",          \"NS\", \"S\", \"NS\", \"S\", \"NS\", \"NS\", \"S\", \"NS\",          \"S\", \"NS\", \"NS\", \"NS\", \"NS\", \"NS\", \"NS\", \"S\",          \"S\", \"S\", \"S\", \"NS\", \"NS\", \"NS\", \"NS\", \"S\",          \"NS\", \"NS\", \"NS\", \"S\", \"S\", \"S\", \"S\", \"S\",          \"S\", \"S\", \"S\")  #read all the files data= read_TOBII(subject, wd)  #split for eyetracker and behavioral data ET= data$ET BD= data$BD"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"prepare-the-data","dir":"Articles","previous_headings":"","what":"Prepare the data","title":"Pupilla_TOBII_ReduceFeatures","text":"bad (?) habit record essential info eyetracker file, :) result, often variables present behavioral file (e.g., response time, condition) must copied eyetracker file, different dimensions (several lines per trial, depending sampling rate). Pupilla utility functions precisely . Let’s move order though. start filling “Event” column, blank except Event changes: Based Event column changing value, can establish trial number (yes, info also missing eyetracker file!). detect_change() simply updates counter every instance parameter “key” appears vector (first time). initial samples assigned trial, shall removed: can start now copying relevant variables ET dataframe. start adding variable Phase (whether trial labelled practice, therefore removed afterwards, experimental). move variable Trial: finally variables make experimental design: (, Condition relevant , rest can skip vignette). can finally start handling preparing signal pupil size! TOBII acquired left right eye. consolidate two one single variable represents average two eyes - judged valid TOBII’s algorithms. TOBII stores pupil size mms, can fetch plausible values (2 7 mms) discard outlier ones straight away. isolate two experimental stages: scrambled images (baseline) vs target images. can now realign timestamps first sample scrambled phase. can see timestamps absolute values, difference really constant. theory trial last 4500 ms, one two reasons missed something last longer, shall discard . Now everything clean, realign Time beginning trial, moment target presented: Finally, moment Group variable added. Furthermore, discard participants present sufficient valid trials; actually seen afterwards, experiment add another task eye movements quality important, exclusions decided based results tasks.","code":"ET$Event= ifelse(ET$Event== \"\", NA, ET$Event) ET= tidyr::fill(ET, Event, .direction = \"down\") ET$Subject= ET$p_ID ET= ET %>%   group_by(Subject) %>%   mutate(Trial= detect_change(Event,                                key= \"scrambled\")) ET= ET[ET$Trial>=0,] #whether it's practice or experiment ET$Phase= copy_variable(\"Phase\") #discard practice ET= ET[ET$Phase== \"experiment\",] BD= BD[BD$Phase== \"experiment\",] ET$Trial= copy_variable(\"Trial\") ET$Condition= copy_variable(\"Condition\") # ET$Cue= copy_variable(\"Cue\") # ET$Accuracy= copy_variable(\"Accuracy\") # ET$Image= copy_variable(\"Image\") # ET$RT = as.numeric(copy_variable(\"RT\")) ET$Pupil= consolidate_signal(ET$PupilSizeLeft, ET$PupilSizeRight,                              ET$PupilValidityLeft, ET$PupilValidityRight,                              strategy = \"conservative\",                              plausible= c(2, 7)) ET= ET[ET$Event %in% c(\"scrambled\", \"target\"),] #head(ET$TimeStamp)  ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Time= c(0,                  cumsum(diff(TimeStamp))))  #head(ET$Time) #range(ET$Time)  ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Anomaly= ifelse(max(Time)>4500, 1, 0))  # (table(ET$p_ID[ET$Anomaly== 1],  #       ET$Trial[ET$Anomaly== 1])) #for 1 participant, the trial around the break...  ET= ET[ET$Anomaly== 0,] ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Time= Time - Time[Event== \"target\"][1])  ET= ET[ET$Time >-1000 & ET$Time<3000,] ET= ET %>% filter(!Subject %in% c(2, 9, 10, 13, 25, 29, 30, 34, 38, 48, 49))  #assign group ET$Group= group[ET$Subject]"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"preprocessing","dir":"Articles","previous_headings":"","what":"Preprocessing","title":"Pupilla_TOBII_ReduceFeatures","text":"can finally move real thing! signal must processed impact artifacts, blinks, etc. reduced. easiest way Pupilla use pre_process() function. may want, however, consider whether specific default parameters applicable data. description parameters, see ?pp_options(). can always change default parameters calling options globally, within function . E.g.: checked defaults, preprocessing requires: ’s ! can check result pipeline visually follows:  can use function Pupilla::check_all_series() plots (, ids trials) saved images path. image, black dots represent raw, initial data. red line depicts instead reconstructed, preprocessed signal. pre_process() simply runs, order, functions deblinking (velocity-based criterion), interpolation, smoothing cubic splines. Trials data points reach given quality threshold set NA; trials can recovered , instead, recovered. , trials couldn’t restore reliable signal, simply discard ! Another common step downsampling, choose bins 25 ms: Next, personally prefer work z-scores instead arbitrary units mms, standardized measure. : last, crucial step baseline subtraction. analogy done paper simply realign traces beginning target presentation phase, just like done Time. extended period advisable. done!","code":"#the default parameters: pp_options() # $thresh # [1] 3 #  # $speed_method # [1] \"z\" #  # $extend_by # [1] 3 #  # $island_size # [1] 4 #  # $extend_blink # [1] 3 #  # $overall_thresh # [1] 0.4 #  # $consecutive_thresh # NULL #  # $spar # [1] 0.7  #this changes the width of the window for smoothing pp_options(\"spar\"= 0.8) #entire preprocessing ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Pupil_pp= pre_process(Pupil, Time)) ET %>% filter(Subject==12 & Trial== 104) %>%   check_series(\"Pupil\", \"Pupil_pp\", \"Time\") #drop ET= ET %>% filter(!is.na(Pupil_pp)) ET$Time= downsample_time(ET$Time, 25)  #summarise the data for the new binned variable ET= ET %>%   group_by(Subject, Group, Condition, Trial, Time) %>%   summarise(Pupil= median(Pupil_pp, na.rm = T)) ET= ET %>%   group_by(Subject) %>%   mutate(Pupil= (Pupil-mean(na.omit(Pupil)))/sd(na.omit(Pupil))) ET= ET %>%   group_by(Subject, Trial) %>%   mutate(Pupil= Pupil - Pupil[Time== 0][1])"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"analysis","dir":"Articles","previous_headings":"","what":"Analysis","title":"Pupilla_TOBII_ReduceFeatures","text":"Briefly, data looks like :  now different paths statistical modelling. original paper choose cluster-based permutation test. approach often computationally-intensive, though works well. approaches involve crossvalidated LMEMs (implemented package Pupilla shown another vignette) feature reduction. Feature reduction norm pupillometry, common branches neuroimaging - e.g., fMRI. works well, data large, reducing dimensions manageable variables work . case pupillometry, signal strongly autocorrelated, particularly appealing. Pupilla can summarise traces PCA ICA follows.","code":""},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"pca","dir":"Articles","previous_headings":"Analysis","what":"PCA","title":"Pupilla_TOBII_ReduceFeatures","text":"traces 40 participants x () 200 trials can summarised PCs (need 3 variables account >98% data!): PC accounts specific share variance, distinctive loadings - can think weighted contribution PC time point, way similar cluster, though graded. can assess loadings directly plot conveniently returned plot_loadings().  loadings first PC, expected, resemble much shape data. trial steady pupil dilation, well captured later timepoints larger weights. sign loadings , instead, arbitrary, well multiply -1. component summarised one score per trial! far manageable uses, e.g. obtain intuitive easy interpret summary scores. Scores can used directly - e.g., correlate experimental variables questionnaires neuroimaging data - used second level analysis (e.g., simple t tests). case Group x Condition interaction, start summarising trial summary scores, scoring difference conditions: PC1:  significant interaction group condition captured first PC! second PC , instead, significant: Features first ones progressively account remaining variance, may thus accomodate subtle differences conditions alter necessarily overall shape pupillary dilation. words, next pcs describe sort contrast functions like one:","code":"data= ET[ET$Time>0,] #remove the baseline dv= \"Pupil\" time= \"Time\" id= \"Subject\" trial= \"Trial\" add= c(\"Group\", \"Condition\") #save to final dataframe Ncomp= NULL #defaults to 95% of variance retained  rf = reduce_PCA(data,                 dv,                 time,                 id,                 trial,                 Ncomp = NULL,                 add) rf$summaryPCA[, 1:4] plot_loadings(\"PC1\", rf) Scores= rf$Scores  Scores= Scores %>%    group_by(id, Group, Condition) %>%    summarise(PC1= mean(PC1), PC2= mean(PC2)) %>%    group_by(id, Group) %>%    reframe(PC1= PC1[Condition== \"Control\"]-PC1[Condition== \"Nicotine-related\"],            PC2= PC2[Condition== \"Control\"]-PC2[Condition== \"Nicotine-related\"]) #plots of the difference ggplot(Scores, aes(x= Group,                    color= Group,                    y= PC1)) +   geom_point(position = position_dodge2(0.3))   t.test(Scores$PC1[Scores$Group== \"Smokers\"],        Scores$PC1[Scores$Group== \"Non smokers\"]) t.test(Scores$PC2[Scores$Group== \"Smokers\"],        Scores$PC2[Scores$Group== \"Non smokers\"]) plot_loadings(\"PC2\", rf)"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"ica","dir":"Articles","previous_headings":"Analysis","what":"ICA","title":"Pupilla_TOBII_ReduceFeatures","text":"Choosing ICA simple ! Pupilla uses ica::icafast independent components analysis. overall explained variance remains PCA. However, single contribution components weighted : words, trust much title loadings plot - refers PCA model:  case first IC first PC similar, scale changes bit, reflect overall dilation trend - , sign loadings really matter (just check direction interpretation data). Results (somehow) similar PCA:","code":"rf2 = reduce_ICA(data,                  dv,                  time,                  id,                  trial,                  Ncomp = NULL,                  center = F,                  add) rf2$ICA$vafs plot_loadings(\"IC1\", rf2) Scores2= rf2$Scores  Scores2= Scores2 %>%    group_by(id, Group, Condition) %>%    summarise(IC1= mean(IC1), IC2= mean(IC2)) %>%    group_by(id, Group) %>%    reframe(IC1= IC1[Condition== \"Control\"]-IC1[Condition== \"Nicotine-related\"],            IC2= IC2[Condition== \"Control\"]-IC2[Condition== \"Nicotine-related\"]) #plots of the difference ggplot(Scores2, aes(x= Group,                    color= Group,                    y= IC1)) +   geom_point(position = position_dodge2(0.3))  t.test(Scores2$IC1[Scores$Group== \"Smokers\"],        Scores2$IC1[Scores$Group== \"Non smokers\"])"},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Pupilla_TOBII_ReduceFeatures","text":"vignette went example use functions Pupilla data, areas encompassing loading, preparing, preprocessing data. Furthermore, novel approach - , , object active research - analyze data presented. approach signal decomposed , manageable scores, explain efficiently (severely autocorrelated) data handful scores. scores can attributed differences pupil size different time points, can explored visually loadings specific components. Another advantage , case multiple components presenting significant effects, weights can backprojected linear combination coefficients loadings (see, details, backprojection package, FCnet). approach therefore potential flexible. approach discussed details accompanying paper.","code":""},{"path":"/articles/Pupilla_TOBII_ReduceFeatures.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Pupilla_TOBII_ReduceFeatures","text":"Packages’ versions:","code":"sessionInfo() # R version 4.2.3 (2023-03-15 ucrt) # Platform: x86_64-w64-mingw32/x64 (64-bit) # Running under: Windows 10 x64 (build 19045) #  # Matrix products: default #  # locale: # [1] LC_COLLATE=Italian_Italy.utf8  LC_CTYPE=Italian_Italy.utf8    LC_MONETARY=Italian_Italy.utf8 LC_NUMERIC=C                   LC_TIME=Italian_Italy.utf8     #  # attached base packages: # [1] stats     graphics  grDevices utils     datasets  methods   base      #  # other attached packages: # [1] tidyr_1.3.0        ggplot2_3.4.1      dplyr_1.1.0        Pupilla_0.0.0.9000 #  # loaded via a namespace (and not attached): #  [1] Rcpp_1.0.10         nloptr_2.0.3        pillar_1.8.1        compiler_4.2.3      tools_4.2.3         boot_1.3-28.1       digest_0.6.31       lme4_1.1-32         nlme_3.1-162        evaluate_0.20       lifecycle_1.0.3     tibble_3.2.0        gtable_0.3.1        lattice_0.20-45     pkgconfig_2.0.3     rlang_1.1.3         Matrix_1.5-3        cli_3.6.0           rstudioapi_0.14     patchwork_1.1.2     yaml_2.3.7          xfun_0.39           fastmap_1.1.1       withr_2.5.0         knitr_1.42          generics_0.1.3      vctrs_0.6.0         lmerTest_3.1-3      grid_4.2.3          tidyselect_1.2.0    glue_1.6.2          R6_2.5.1            fansi_1.0.4         rmarkdown_2.20      minqa_1.2.5         purrr_1.0.1         magrittr_2.0.3      settings_0.2.7      scales_1.2.1        htmltools_0.5.4     MASS_7.3-58.2       splines_4.2.3       colorspace_2.1-0    numDeriv_2016.8-1.1 utf8_1.2.3          munsell_0.5.0"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Elvio Blini. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blini E (2024). Pupilla: Process Analyze Eye-tracking Pupillometry Data. R package version 0.0.0.9001, https://github.com/EBlini/Pupilla.","code":"@Manual{,   title = {Pupilla: Process and Analyze Eye-tracking and Pupillometry Data},   author = {Elvio Blini},   year = {2024},   note = {R package version 0.0.0.9001},   url = {https://github.com/EBlini/Pupilla}, }"},{"path":"/index.html","id":"pupilla","dir":"","previous_headings":"","what":"Process and Analyze Eye-tracking and Pupillometry Data","title":"Process and Analyze Eye-tracking and Pupillometry Data","text":"R package processing analysis eye-tracking pupillometry data.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Process and Analyze Eye-tracking and Pupillometry Data","text":"package currently available GitHub. installation requires R package devtools.","code":"# install.packages(\"devtools\") devtools::install_github(\"EBlini/Pupilla\")"},{"path":"/index.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Process and Analyze Eye-tracking and Pupillometry Data","text":"collection functions wrappers useful preprocessing analyze eyetracking data, special focus pupillometry. functions designed data TOBII’s eyetrackers collected third-part experiment builders OpenSesame. functions considered development: requests suggestions welcome, :) . useful references, example results functions, see Blini Zorzi, 2023.","code":""},{"path":"/reference/check_all_series.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"Convenience function check series across IDs Trials, saves multiple plots current path creating folders subfolders hopefully meaningful way. Note massive data take time, may want debug first subset data. defaults 'ggsave', used internally, now bit stiff may become flexible future. 'check_series' function invoked plots, thus may want check relative help page.","code":""},{"path":"/reference/check_all_series.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"","code":"check_all_series(data, ID, Trial, series1, series2, time)"},{"path":"/reference/check_all_series.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"data Mandatory, differently 'check_series'. IDs Trials levels around loop set retrieved . ID string indicating name ID column. Trial string indicating name Trial column. series1 Unlike 'check_series', must string indicating name first time series plot. series2 Unlike 'check_series', must string indicating name second time series plot. time Unlike 'check_series', must string indicating elapsed time, used x-axis.","code":""},{"path":"/reference/check_all_series.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenience function to check series across IDs and Trials, and save a plot in the current path — check_all_series","text":"plot.","code":""},{"path":"/reference/check_series.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots two time series against each other — check_series","title":"Plots two time series against each other — check_series","text":"function plots two time series . intended use generally check original vs. preprocessed data. first series plotted black line, second one - typically reconstructed series - red line. Nas show interruptions lines. function can used within dplyr's style pipes - case 'data' can omitted variables must provided quoted variables' names - standard vectors may provided - case 'data' NULL args passed name.","code":""},{"path":"/reference/check_series.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots two time series against each other — check_series","text":"","code":"check_series(data, series1, series2, time)"},{"path":"/reference/check_series.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots two time series against each other — check_series","text":"data Optional. Can omitted passed dplyr's style pipelines ('.'), case arguments passed quoted variables' names. series1 vector variable values first time series. plotted means black line. Typically, original data. series2 vector variable values second time series. plotted means red line. Typically, processed data. time vector variable indicating elapsed time, used x axis.","code":""},{"path":"/reference/check_series.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots two time series against each other — check_series","text":"plot.","code":""},{"path":"/reference/consolidate_signal.html","id":null,"dir":"Reference","previous_headings":"","what":"Consolidate pupil data according to different heuristics — consolidate_signal","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"Mostly used, e.g., pupil data available eyes one needs single variable. Results weighted vectors signal validity provided eye-trackers. absent, signals valid assumed.","code":""},{"path":"/reference/consolidate_signal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"","code":"consolidate_signal(   s1,   s2,   v1,   v2,   strategy = c(\"conservative\", \"liberal\", \"pick_best\"),   plausible = NULL )"},{"path":"/reference/consolidate_signal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"s1 vector first signal. s2 vector second signal. v1 vector weights first signal. v2 vector weights second signal. strategy strategy mixing two signals. Conservative takes mean signals valid. Liberal additionally take one valid signal even valid. Pick_best chooses best overall signal (valid often) disregard one two valid. plausible vector length 2 defining range plausible values pupil size. provided, values outside range set NA.","code":""},{"path":"/reference/consolidate_signal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Consolidate pupil data according to different heuristics — consolidate_signal","text":"numeric vector consolidated pupil size NAs available.","code":""},{"path":"/reference/copy_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"Sometimes info relevant eye-tracking file found associated behavioral file. data.frames different dimensions, thus copying one variable another can cumbersome. function job expanding relevant information accordingly exploits constraints two files. task performed ID separately requires \"Trial\" variable used calculate amount required expansion data.","code":""},{"path":"/reference/copy_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"","code":"copy_variable(   var_name,   id_var = \"p_ID\",   constrained_var = \"Trial\",   larger_df = ET,   smaller_df = BD )"},{"path":"/reference/copy_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"var_name string suggesting variable look smaller data.frame (usually behavioral one) copy larger data.frame (usually eye-tracker one). id_var name ID variable grouping variable assignment must separated (e.g., performed participant). Can NULL grouping. constrained_var name variable represents available costraint. example, can Trial number 'var_name' expanded value value Trial number. larger_df larger data.frame. output vector match number rows dataframe. Typically, eye-tracker dataframe. smaller_df smaller dataframe includes 'var_name'.","code":""},{"path":"/reference/copy_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"copy a variable from one data.frame to another of different length given ID and Trial constraints — copy_variable","text":"vector 'length= nrow(larger_df)'.","code":""},{"path":"/reference/decode_signal.html","id":null,"dir":"Reference","previous_headings":"","what":"Highlights and test the time-course of effects through crossvalidation — decode_signal","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"function meant implement, roughly assurance full compatibility whatsoever, procedure proposed Mathôt Vilotijević (2022, Behavior Research Methods). First, trial (.e., one complete time series) assigned one fold deterministic fashion (first trial first fold, second trial second fold, etc.). , regard conditions distributed across folds, .e. data may slightly unbalanced; thus, think carefully whether strategy applies design (e.g., blocked conditions). , data separated time-point, LMEM specified 'formula' parameter, passed 'lmerTest::lmer', performed iteratively leaving one fold . results table, many rows effects implied formula 'nfolds', summarising time point peak t-value (absolute value) trained folds. separate table peak values tested: dependent variable becomes, fold, variable provided 'dv' specific peak. Another LMEM computed using newly created variable. One problem approach peak values can places, depending data. Also, choosing time-points based maximum value training dataset can occasionally decrease precision estimate give overfitting. may use approach confident specific effect effect specific window; effects multiple windows - e.g., early late impact pupil size - may properly captured approach. Therefore, addition procedure, coarse consensus seek assessing, across folds effects, time points resulted t-values certain threshold; time points pop consistently across folds (e.g.,= 'consensus_thresh' % times), time point retained; time-pointsretained consensus collapsed (averaged), final LMEM performed withthese time points. can interpreted similarly cluster-basedpermutation test (although ).","code":""},{"path":"/reference/decode_signal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"","code":"decode_signal(   data,   formula,   dv,   time,   id,   trial,   nfolds = 4,   t_thresh = 2,   consensus_thresh = 0.75 )"},{"path":"/reference/decode_signal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"data data.frame containing necessary variables. formula 'lme4'-style formula, passed string. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. nfolds Number folds split trials . Defaults 4. t_thresh Used seek consensus: minimum t-value required push time-point forward. consensus_thresh minimum proportion time-points must 't_thresh' across folds order keep time-point consensus.","code":""},{"path":"/reference/decode_signal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal","text":"list including: peaks retained (left-) fold; test retained, cross-validated peaks; test consensus time-points, ; list time-points retained consensus effect.","code":""},{"path":"/reference/decode_signal_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"'decode_signal()' except powered 'glmer()' thus performs generalized LMEMs.","code":""},{"path":"/reference/decode_signal_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"","code":"decode_signal_g(   data,   formula,   dv,   time,   id,   trial,   nfolds = 4,   t_thresh = 2,   consensus_thresh = 0.75,   ... )"},{"path":"/reference/decode_signal_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"data data.frame containing necessary variables. formula 'lme4'-style formula, passed string. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. nfolds Number folds split trials . Defaults 4. t_thresh Used seek consensus: minimum t-value required push time-point forward. consensus_thresh minimum proportion time-points must 't_thresh' across folds order keep time-point consensus. ... params 'glmer()', e.g. \"family\".","code":""},{"path":"/reference/decode_signal_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Highlights and test the time-course of effects through crossvalidation — decode_signal_g","text":"list including: peaks retained (left-) fold; test retained, cross-validated peaks; test consensus time-points, ; list time-points retained consensus effect.","code":""},{"path":"/reference/detect_change.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect a change in a column, and returns an incremental counter — detect_change","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"Mostly used, e.g., case ET file provide Trial number column. function monitors occurrences 'key' value , value appears first time, increases counter 1. example, return counter first occurrences \"target\" \"Event\" column, thus returning putative trial number assuming target repeated iteration. default, column track filled downward. Also, empty lines changed NA. final remark, may need clean lines assigned trial (sometimes, e.g., eyetracker needs time warm ).","code":""},{"path":"/reference/detect_change.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"","code":"detect_change(vector, key)"},{"path":"/reference/detect_change.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"vector vector variable tracked. key Value track, first repetition update counter.","code":""},{"path":"/reference/detect_change.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect a change in a column, and returns an incremental counter — detect_change","text":"numeric vector returning counter - function can thus used tidyverse-style pipelines grouping (e.g., ID).","code":""},{"path":"/reference/downsample_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode a Time variable to a different granularity — downsample_time","title":"Recode a Time variable to a different granularity — downsample_time","text":"time variable passed function corresponding downsampled time bin returned. One 'to_ms' 'to_hz' must null","code":""},{"path":"/reference/downsample_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode a Time variable to a different granularity — downsample_time","text":"","code":"downsample_time(Time, to_ms = 25, to_hz = NULL)"},{"path":"/reference/downsample_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode a Time variable to a different granularity — downsample_time","text":"Time vector variable indicating elapsed time, ms, aligned origin - .e., timestamp. to_ms many ms bins must . to_hz many hertz new sampling rate .","code":""},{"path":"/reference/downsample_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode a Time variable to a different granularity — downsample_time","text":"numeric time vector recoded time bins.","code":""},{"path":"/reference/interpolate.html","id":null,"dir":"Reference","previous_headings":"","what":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"used linearly interpolate data provided successful quality controls. controls met, returned vector vector equal length composed NAs. Quality checks general (.e., overall percentage available non NA data) relative consecutive gaps signal, must exceed given threshold. Thresholds refer maximum rate (percentage) entries allowed NAs; results interpolated thresholds.","code":""},{"path":"/reference/interpolate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"","code":"interpolate(   vector,   extend_blink = pp_options(\"extend_blink\"),   overall_thresh = pp_options(\"overall_thresh\"),   consecutive_thresh = pp_options(\"consecutive_thresh\") )"},{"path":"/reference/interpolate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"vector vector interpolate. extend_blink NAs extended many samples prior interpolation. gets rid signal may compromised close proximity blink. overall_thresh Overall quality threshold: e.g., total amount data allowed missing original vector. consecutive_thresh Consecutive gaps signal: e.g., total amount data allowed missing original vector consecutively.","code":""},{"path":"/reference/interpolate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linearly interpolate signal provided quality checks are met, else only returns NAs — interpolate","text":"numeric vector interpolated data NAs quality checks met.","code":""},{"path":"/reference/plot_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot loadings of a reduced time-series — plot_loadings","title":"Plot loadings of a reduced time-series — plot_loadings","text":"function active development. meant depict loadings components obtained reducing pupillary time-series, ease interpretation.","code":""},{"path":"/reference/plot_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot loadings of a reduced time-series — plot_loadings","text":"","code":"plot_loadings(name, data)"},{"path":"/reference/plot_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot loadings of a reduced time-series — plot_loadings","text":"name string indicating component depict (e.g., \"PC1\"). data object returned , e.g., 'reduce_PCA'.","code":""},{"path":"/reference/plot_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot loadings of a reduced time-series — plot_loadings","text":"plot powered 'ggplot2'.","code":""},{"path":"/reference/pp_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set or get options for Pupilla's preprocessing parameters — pp_options","title":"Set or get options for Pupilla's preprocessing parameters — pp_options","text":"Set get options Pupilla's preprocessing parameters","code":""},{"path":"/reference/pp_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set or get options for Pupilla's preprocessing parameters — pp_options","text":"","code":"pp_options(...)"},{"path":"/reference/pp_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set or get options for Pupilla's preprocessing parameters — pp_options","text":"thresh speed_clean Threshold (z point absolute value) values marked NA. speed_method speed_clean Whether 'thresh' z-score ('z'), deviant values omitted , values threshold ('z-dynamic'). 'abs' used instead precise absolute value speed supplied. extend_by speed_clean Number samples starting deviant speed values stripped (e.g., signal proximity blinks may biased well). island_size speed_clean Islands signal midst NAs removed smaller equal threshold (amount samples). extend_blink interpolate NAs extended many samples prior interpolation. gets rid signal may compromised close proximity blink. overall_thresh interpolate Overall quality threshold: e.g., total amount data allowed missing original vector. consecutive_thresh interpolate Consecutive gaps signal: e.g., total amount data allowed missing original vector consecutively. spar smooth Smoothing factor 'smooth.spline()'.","code":""},{"path":"/reference/predict_feature.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicts features' scores from a model — predict_feature","title":"Predicts features' scores from a model — predict_feature","text":"development. function meant predict scores features obtained trained model one returned 'reduce_*' family functions. particular, function ideally work technique implemented far (PCA, rPCA, ICA) whether scaling centering required. function used within stringent crossclassification approach (scores computed) anew, even different tasks check whether different signatures can observed independent pool data. takes input \"time\" argument ensure timepoints used model compute loadings match, function returns error.","code":""},{"path":"/reference/predict_feature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicts features' scores from a model — predict_feature","text":"","code":"predict_feature(vector, time, model)"},{"path":"/reference/predict_feature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicts features' scores from a model — predict_feature","text":"vector vector variable transformed according given model. Usually pupil dimension trial/condition. time vector variable indicating elapsed time. loadings' names model model Object returned 'reduce_*', e.g. 'reduce_PCA()'.","code":""},{"path":"/reference/predict_feature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicts features' scores from a model — predict_feature","text":"numeric vector scores - many loadings model.","code":""},{"path":"/reference/pre_process.html","id":null,"dir":"Reference","previous_headings":"","what":"A convenience function to preprocess pupillometry data — pre_process","title":"A convenience function to preprocess pupillometry data — pre_process","text":"function calls, order, 'speed_clean', 'interpolate', 'smooth_vector' packages. Parameters can changed package options, .e. 'Pupilla::pp_options()'. Warning, best preprocessing parameters may deviate defaults used , mindful!","code":""},{"path":"/reference/pre_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A convenience function to preprocess pupillometry data — pre_process","text":"","code":"pre_process(vector, time)"},{"path":"/reference/pre_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A convenience function to preprocess pupillometry data — pre_process","text":"vector vector variable cleaned time vector variable indicating elapsed time, needed compute velocity.","code":""},{"path":"/reference/pre_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A convenience function to preprocess pupillometry data — pre_process","text":"numeric vector processed requested per default. .","code":""},{"path":"/reference/read_eyelink.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"two type data usually separate sometimes must merged create one single file eyetracking experimental details (e.g., conditions), unless specified via code experiment builder. function written OpenSesame-like csv files mind, though compatibility programs (e.g., e-prime) may achieved provided files converted csv format. optimized Windows machines - may encounter address errors Macs.","code":""},{"path":"/reference/read_eyelink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"","code":"read_eyelink(   ID,   keep_events = NULL,   path = getwd(),   start_behavior = \"subject-\",   start_eyelink = \"sub_\",   separate_behavioral = TRUE,   import_all = T )"},{"path":"/reference/read_eyelink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"ID integer corresponding one participant's ID. attached current path order locate two files read. Also, One variable named p_ID attached ET BD files. vector supplied, files read lapply merged. keep_events character vector specifying events kept. hard assumption experimental phases recorded messages events$messages slot returned 'eyelinkReader::read_edf()'. path Defaults getwd() can specified otherwise. Files searched starting location. start_behavior string, defaults \"subject-\". Usually files start string, regardless nature. Usually names built concatenating path, start_filename, ID, .csv. start_eyelink string, defaults \"subject-\". Usually files start string, regardless nature. Usually names built concatenating path, start_eyelink, ID, .edf. separate_behavioral defaults TRUE. FALSE, reads eye-tracking data import_all TRUE (default) import blink fixation data computed eyelink.","code":""},{"path":"/reference/read_eyelink.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"list one two DFs, one eye-tracking data, one behavioral data (requested).","code":""},{"path":"/reference/read_eyelink.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reads and imports eyelink eye-tracking and behavioral data — read_eyelink","text":"function wrapper around 'eyelinkReader::read_edf()' must installed. order use package, eyelink proprietary code must installed well (relevant scripts available eyelink forum)","code":""},{"path":"/reference/read_TOBII.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"two type data usually separate sometimes must merged create one single file eyetracking experimental details (e.g., conditions), unless specified via code experiment builder. function written OpenSesame-like csv files mind, though compatibility programs (e.g., e-prime) may achieved provided files converted csv format. optimized Windows machines - may encounter address errors Macs.","code":""},{"path":"/reference/read_TOBII.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"","code":"read_TOBII(   ID,   path = getwd(),   start_filename = \"subject-\",   append_TOBII = \"_TOBII_output.tsv\",   skip = 7,   separate_behavioral = TRUE )"},{"path":"/reference/read_TOBII.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"ID integer corresponding one participant's ID. attached current path order locate two files read. Also, One variable named p_ID attached ET BD files. vector supplied, files read lapply merged. path Defaults getwd() can specified otherwise. Files searched starting location. start_filename string, defaults \"subject-\". Usually files start string, regardless nature. Usually names built concatenating path, start_filename, ID, append_TOBII (eye-tracking data, else \".csv\"). append_TOBII string, defaults \"_TOBII_output.tsv\" indicates text tells eye-tracking behavioral files apart. Usually names built concatenating path, start_filename, ID, append_TOBII (eye-tracking data, else \".csv\"). skip Integer. amount lines skip eye-tracking file, .e. many lines header encountered. passed data.table::fread(). separate_behavioral defaults TRUE. FALSE, reads eye-tracking data","code":""},{"path":"/reference/read_TOBII.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads and imports TOBII eye-tracking and behavioral data — read_TOBII","text":"list one two DFs, one eye-tracking data, one behavioral data (requested).","code":""},{"path":"/reference/reduce_ICA.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce time-series to few Independent Components — reduce_ICA","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"function active development. meant reduce entire time-series normalized baseline-corrected pupillary data just scores obtained Independent Component Analysis. ICA effective way reduce data dimensionality manageable dependent variables, may additionally help precise estimates (fingerprints) pupil signal underlying cognitive processes. functions use 'ica::icafast'.","code":""},{"path":"/reference/reduce_ICA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"","code":"reduce_ICA(   data,   dv,   time,   id,   trial,   Ncomp = NULL,   center = FALSE,   scale = FALSE,   add )"},{"path":"/reference/reduce_ICA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"data data.frame containing necessary variables. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. Ncomp Number components retain. default (NULL) automatically retains 95% explained variance. Ncomp== \"\" returns components. Ncomp <1 interpreted user wishes retain given proportion variance (e.g. 0.6). center Whether variables, .e. pupil size timepoint, centered beforehand. Defaults FALSE assuming measures already baseline-corrected. scale Whether variables, .e. pupil size timepoint, centered beforehand. Defaults FALSE assuming measures already baseline-corrected. add String(s) indicating variables names, , appendend scores dataframe.","code":""},{"path":"/reference/reduce_ICA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce time-series to few Independent Components — reduce_ICA","text":"list including processed data, scores loadings dataframes, ICA object useful prediction new data.","code":""},{"path":"/reference/reduce_PCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce time-series to few Principal Components — reduce_PCA","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"function active development. meant reduce entire time-series normalized baseline-corrected pupillary data just scores obtained Principal Component Analysis. PCA effective way reduce data dimensionality manageable dependent variables, may additionally help precise estimates (fingerprints) pupil signal underlying cognitive processes.","code":""},{"path":"/reference/reduce_PCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"","code":"reduce_PCA(   data,   dv,   time,   id,   trial,   Ncomp = NULL,   center = FALSE,   scale = FALSE,   add )"},{"path":"/reference/reduce_PCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"data data.frame containing necessary variables. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. Ncomp Number components retain. default (NULL) automatically retains 95% explained variance. Ncomp== \"\" returns components. Ncomp <1 interpreted user wishes retain given proportion variance (e.g. 0.6). center Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. scale Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. add String(s) indicating variables names, , appendend scores dataframe.","code":""},{"path":"/reference/reduce_PCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce time-series to few Principal Components — reduce_PCA","text":"list including processed data, scores loadings dataframes, PCA object useful prediction new data.","code":""},{"path":"/reference/reduce_rPCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"function active development. meant reduce entire time-series normalized baseline-corrected pupillary data just scores obtained rotated Principal Component Analysis. PCA effective way reduce data dimensionality manageable dependent variables, may additionally help precise estimates (fingerprints) pupil signal underlying cognitive processes. Rotation oblique sense force PCs orthogonal may help interpretation resulting loadings. function uses 'psych::principal()' may differ standardization performed.","code":""},{"path":"/reference/reduce_rPCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"","code":"reduce_rPCA(   data,   dv,   time,   id,   trial,   Ncomp = NULL,   center = FALSE,   scale = FALSE,   rotate = \"promax\",   add )"},{"path":"/reference/reduce_rPCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"data data.frame containing necessary variables. dv string indicating name dependent variable. time string indicating name time variable. id string indicating name id (participant) variable. trial string indicating name trial variable. Ncomp Number components retain. default (NULL) automatically retains 95% explained variance. Note , however, based unrotated PCA, rotated variables generally explain less variance. Ncomp== \"\" returns components. Ncomp <1 interpreted user wishes retain given proportion variance (e.g. 0.6), unrotated PCA used find number components. center Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. Note impacts summaryPCA number components retained psych uses covariance matrix. scale Whether variables, .e. pupil size timepoint, scaled beforehand. Defaults FALSE assuming measures already normalized (z-scores) baseline-corrected. Note impacts summaryPCA number components retained psych uses covariance matrix. rotate Defaults \"promax\" oblique rotation. set \"none\" PCA style 'psych' package. Accepts accepted 'psych::principal()'. add String(s) indicating variables names, , appendend scores dataframe.","code":""},{"path":"/reference/reduce_rPCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce time-series to few (rotated) Principal Components — reduce_rPCA","text":"list including processed data, scores loadings dataframes, PCA object useful prediction new data.","code":""},{"path":"/reference/smooth_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth a time series through cubic splines — smooth_vector","title":"Smooth a time series through cubic splines — smooth_vector","text":"can used simple smoothing function, case eyetracking data can used low-pass filter, useful correct artifacts, blinks, etc.","code":""},{"path":"/reference/smooth_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth a time series through cubic splines — smooth_vector","text":"","code":"smooth_vector(vector, time, spar = pp_options(\"spar\"))"},{"path":"/reference/smooth_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth a time series through cubic splines — smooth_vector","text":"vector vector variable smoothed. time vector variable indicating elapsed time. spar Smoothing factor 'smooth.spline()'.","code":""},{"path":"/reference/smooth_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth a time series through cubic splines — smooth_vector","text":"numeric vector smoothed requested.","code":""},{"path":"/reference/speed_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Help identifying artifacts with a speed-based criterion — speed_clean","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"signal vector stripped values exceeding given threshold, computed basis absolute speed signal increase decrease.","code":""},{"path":"/reference/speed_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"","code":"speed_clean(   vector,   time,   thresh = pp_options(\"thresh\"),   speed_method = pp_options(\"speed_method\"),   extend_by = pp_options(\"extend_by\"),   island_size = pp_options(\"island_size\") )"},{"path":"/reference/speed_clean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"vector vector variable cleaned time vector variable indicating elapsed time, needed compute velocity. thresh Threshold (z point absolute value) values marked NA. speed_method Whether 'thresh' z-score ('z'), deviant values omitted , values threshold ('z-dynamic'). 'abs' used instead precise absolute value speed supplied. extend_by Number samples starting deviant speed values stripped (e.g., signal proximity blinks may biased well). island_size Islands signal midst NAs removed smaller equal threshold (amount samples).","code":""},{"path":"/reference/speed_clean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Help identifying artifacts with a speed-based criterion — speed_clean","text":"numeric vector cleaned requested.","code":""}]

time_list= lapply(time_lev, function(x){
ind= DF$time %in% x
DF[ind,]
})
#now create a function that, given data, fits the models for each fold
fit_folds= function(data2, nfolds){
data2$pred= NA
res= vector("list", nfolds)
for(i in 1:nfolds){
train= data2[!data2$Fold %in% i,]
#needless here
#test= data2[data2$Fold %in% i,]
#train
mod= NULL
mod= tryCatch(lmerTest::lmer(formula,
train),
error= function(dummy)(mod= NULL))
if(is.null(mod))(res[[i]]= NULL) else {
res[[i]]= car::Anova(mod, type= type, test.statistic= "F")
}
}
return(res)
}
#now fit for every time point and fold
all_fit= lapply(time_list, function(x)fit_folds(x, nfolds))
library("reticulate")
library("dplyr")
library("Pupilla")
library("ggplot2")
library("emmeans")
library("lmerTest")
# #create python environment
#conda_create("my_env")
#use_miniconda("my_env")
# #install packages in the environment
# py_install("pandas")
# py_install("datamatrix")
options(dplyr.summarise.inform = FALSE)
reticulate::repl_python()
from datamatrix import io, convert
address= "C:\\Users\\blini\\Downloads\\mathot crossval prova\\zhou_et_al_2021.pkl"
data= io.readpickle(address)
data= convert.to_pandas(data)
quit
use_miniconda("my_env")
reticulate::repl_python()
from datamatrix import io, convert
address= "C:\\Users\\blini\\Downloads\\mathot crossval prova\\zhou_et_al_2021.pkl"
data= io.readpickle(address)
data= convert.to_pandas(data)
quit
library("reticulate")
library("dplyr")
library("Pupilla")
library("ggplot2")
library("emmeans")
library("lmerTest")
# #create python environment
#conda_create("my_env")
use_miniconda("my_env")
# #install packages in the environment
# py_install("pandas")
# py_install("datamatrix")
options(dplyr.summarise.inform = FALSE)
reticulate::repl_python()
from datamatrix import io, convert
address= "C:\\Users\\blini\\Downloads\\mathot crossval prova\\zhou_et_al_2021.pkl"
data= io.readpickle(address)
data= convert.to_pandas(data)
quit
DF= py$data #bring to R
DF2 = lapply(1:nrow(DF), function(x) {
res = data.frame(
Pupil = as.vector(DF$pupil[[x]]),
Set_size = DF$set_size[x],
Subject = DF$subject_nr[x],
Color_type = DF$color_type[x],
Time = seq(0, 3, length = 300)
)
return(res)
})
DF2= do.call(rbind, DF2)
DF2= DF2 %>%
group_by(Subject, Time) %>%
mutate(Trial= 1:n())
DF2= data.frame(DF2)
DF2$Set_size= as.factor(DF2$Set_size)
setwd()
setwd(choose.dir())
saveRDS(DF2, "zhou et al. 2022.RData")
readRDS("data//zhou et al. 2022.RData")
library(Pupilla)
devtools::load_all(".")
library("pkgdown")
clean_site()
build_site()
clean_site()
build_site()
clean_site()
build_site()
clean_site()
build_site()
install.packages(c("afex", "askpass", "BayesFactor", "blogdown", "bookdown", "brew", "brio", "broom", "bslib", "buildmer", "cachem", "caret", "checkmate", "cli", "clock", "coda", "commonmark", "config", "cowplot", "cpp11", "credentials", "crosstalk", "data.table", "datawizard", "DBI", "dbplyr", "deldir", "desc", "deSolve", "digest", "downlit", "dplyr", "DT", "dtplyr", "e1071", "ellipse", "emmeans", "evaluate", "eyelinkReader", "FactoMineR", "fansi", "fastICA", "fontawesome", "fs", "future", "future.apply", "gargle", "gdata", "gert", "GGally", "ggbeeswarm", "ggeffects", "ggplot2", "ggpmisc", "ggpp", "ggrepel", "glmnet", "glmnetUtils", "glue", "googledrive", "googlesheets4", "graphlayouts", "gtable", "gtools", "hardhat", "haven", "heplots", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "igraph", "insight", "interp", "jsonlite", "keras", "labeling", "later", "lava", "lavaan", "lifecycle", "listenv", "lme4", "lubridate", "markdown", "MatrixModels", "matrixStats", "minqa", "modelr", "mvtnorm", "nnls", "openssl", "ordinal", "pan", "parallelly", "parameters", "patchwork", "pbapply", "performance", "permutes", "pillar", "plotrix", "pls", "plyr", "polyclip", "pracma", "prettyunits", "pROC", "processx", "prodlim", "profvis", "progress", "progressr", "promises", "ps", "psych", "purrr", "quantreg", "R.oo", "R.utils", "ragg", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "recipes", "rematch", "remotes", "reprex", "reticulate", "rmarkdown", "RNifti", "roxygen2", "rprojroot", "rstudioapi", "Rtsne", "sandwich", "sass", "scales", "scatterplot3d", "servr", "shiny", "sp", "splus2R", "stringi", "stringr", "sys", "systemfonts", "tensorflow", "terra", "testthat", "textshaping", "tfruns", "tibble", "tidygraph", "tidyr", "timechange", "timeDate", "tinytex", "tzdb", "ucminf", "usethis", "utf8", "uuid", "vctrs", "vipor", "viridis", "viridisLite", "vroom", "waldo", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("afex", "askpass", "BayesFactor", "blogdown", "bookdown", "brew", "brio", "broom", "bslib", "buildmer", "cachem", "caret", "checkmate", "cli", "clock", "coda", "commonmark", "config", "cowplot", "cpp11", "credentials", "crosstalk", "data.table", "datawizard", "DBI", "dbplyr", "deldir", "desc", "deSolve", "digest", "downlit", "dplyr", "DT", "dtplyr", "e1071", "ellipse", "emmeans", "evaluate", "eyelinkReader", "FactoMineR", "fansi", "fastICA", "fontawesome", "fs", "future", "future.apply", "gargle", "gdata", "gert", "GGally", "ggbeeswarm", "ggeffects", "ggplot2", "ggpmisc", "ggpp", "ggrepel", "glmnet", "glmnetUtils", "glue", "googledrive", "googlesheets4", "graphlayouts", "gtable", "gtools", "hardhat", "haven", "heplots", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "igraph", "insight", "interp", "jsonlite", "keras", "labeling", "later", "lava", "lavaan", "lifecycle", "listenv", "lme4", "lubridate", "markdown", "MatrixModels", "matrixStats", "minqa", "modelr", "mvtnorm", "nnls", "openssl", "ordinal", "pan", "parallelly", "parameters", "patchwork", "pbapply", "performance", "permutes", "pillar", "plotrix", "pls", "plyr", "polyclip", "pracma", "prettyunits", "pROC", "processx", "prodlim", "profvis", "progress", "progressr", "promises", "ps", "psych", "purrr", "quantreg", "R.oo", "R.utils", "ragg", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "recipes", "rematch", "remotes", "reprex", "reticulate", "rmarkdown", "RNifti", "roxygen2", "rprojroot", "rstudioapi", "Rtsne", "sandwich", "sass", "scales", "scatterplot3d", "servr", "shiny", "sp", "splus2R", "stringi", "stringr", "sys", "systemfonts", "tensorflow", "terra", "testthat", "textshaping", "tfruns", "tibble", "tidygraph", "tidyr", "timechange", "timeDate", "tinytex", "tzdb", "ucminf", "usethis", "utf8", "uuid", "vctrs", "vipor", "viridis", "viridisLite", "vroom", "waldo", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("afex", "askpass", "BayesFactor", "blogdown", "bookdown", "brew", "brio", "broom", "bslib", "buildmer", "cachem", "caret", "checkmate", "cli", "clock", "coda", "commonmark", "config", "cowplot", "cpp11", "credentials", "crosstalk", "data.table", "datawizard", "DBI", "dbplyr", "deldir", "desc", "deSolve", "digest", "downlit", "dplyr", "DT", "dtplyr", "e1071", "ellipse", "emmeans", "evaluate", "eyelinkReader", "FactoMineR", "fansi", "fastICA", "fontawesome", "fs", "future", "future.apply", "gargle", "gdata", "gert", "GGally", "ggbeeswarm", "ggeffects", "ggplot2", "ggpmisc", "ggpp", "ggrepel", "glmnet", "glmnetUtils", "glue", "googledrive", "googlesheets4", "graphlayouts", "gtable", "gtools", "hardhat", "haven", "heplots", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "igraph", "insight", "interp", "jsonlite", "keras", "labeling", "later", "lava", "lavaan", "lifecycle", "listenv", "lme4", "lubridate", "markdown", "MatrixModels", "matrixStats", "minqa", "modelr", "mvtnorm", "nnls", "openssl", "ordinal", "pan", "parallelly", "parameters", "patchwork", "pbapply", "performance", "permutes", "pillar", "plotrix", "pls", "plyr", "polyclip", "pracma", "prettyunits", "pROC", "processx", "prodlim", "profvis", "progress", "progressr", "promises", "ps", "psych", "purrr", "quantreg", "R.oo", "R.utils", "ragg", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "recipes", "rematch", "remotes", "reprex", "reticulate", "rmarkdown", "RNifti", "roxygen2", "rprojroot", "rstudioapi", "Rtsne", "sandwich", "sass", "scales", "scatterplot3d", "servr", "shiny", "sp", "splus2R", "stringi", "stringr", "sys", "systemfonts", "tensorflow", "terra", "testthat", "textshaping", "tfruns", "tibble", "tidygraph", "tidyr", "timechange", "timeDate", "tinytex", "tzdb", "ucminf", "usethis", "utf8", "uuid", "vctrs", "vipor", "viridis", "viridisLite", "vroom", "waldo", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
library(Pupilla)
#' Plot loadings of a reduced time-series
#'
#' This function is under active development. It is
#' meant to depict the loadings of components obtained by reducing
#' pupillary time-series, as to ease interpretation.
#'
#' @param name A string indicating the component to depict (e.g., "PC1").
#' @param data An object as returned by, e.g., 'reduce_PCA'.
#' @return A plot powered by 'ggplot2'.
#'
#' @export
plot_loadings= function(name,
data){
#set data
dv= data$Loadings[, name]
time= as.numeric(rownames(data$Loadings))
DF= data.frame(Time= time, dv= dv)
#pretty color scheme
percentile= ecdf(abs(DF$dv))
DF$Color= percentile(abs(DF$dv) + min(abs(DF$dv)))
limit= c(min(dv), max(dv))
if(limit[2]<0)(limit[2]= 0)
if(limit[1]>0)(limit[1]= 0)
if("ICA" %in% names(data)){
cp= gsub("[[:digit:]]","",name)
cp= as.numeric(gsub(cp,"",name))
ev= round(data$ICA$vafs[cp], 2)
} else {
ev= round(data$summaryPCA["Proportion of Variance", name], 2)
}
#theme
commonTheme= list(#theme_bw(),
ggplot2::theme(text= ggplot2::element_text(size= 16,
face="bold")),
ggplot2::xlab("Time (ms)"),
ggplot2::ylab("Loading"),
ggplot2::ylim(limit),
ggplot2::ggtitle(name,
subtitle= paste0("Explained variance: ",
ev))
)
p=
ggplot2::ggplot(DF, ggplot2::aes(x= Time, y= dv)) +
ggplot2::geom_point(ggplot2::aes(color= Color),
size= 1.3, show.legend = F) +
ggplot2::scale_color_gradient(low = "yellow", high = "red") +
ggplot2::geom_hline(yintercept = 0,
color= "black", linetype= "dashed",
linewidth= 1.2) +
commonTheme
return(p)
}
# Chunk 1: setup
#knitr::knit_engines$set(python= reticulate::eng_python)
options(width = 999)
Sys.setenv(LANG = "en")
knitr::opts_chunk$set(
echo= T,
#fig.path = "images/",
eval= T,
fig.width = 7,
fig.height = 7
)
# Chunk 2
library("dplyr")
library("Pupilla")
library("ggplot2")
library("emmeans")
library("lmerTest")
library("zoo")
options(dplyr.summarise.inform = FALSE)
# Chunk 7
DF2= readRDS("data//zhou et al 2022.RData")
DF2= readRDS("data//zhou et al 2022.RData")
DF2= readRDS("data/zhou et al 2022.RData")
getwd()
setwd(choose.dir())
DF2= readRDS("data/zhou et al 2022.RData")
sum(is.na(DF2$Pupil))
DF2= DF2 %>%
group_by(Subject, Trial) %>%
mutate(Pupil= zoo::na.approx(Pupil, na.rm = F))
sum(is.na(DF2$Pupil))
DF2 %>%
group_by(Subject, Time, Color_type, Set_size) %>%
summarise(Pupil= mean(Pupil, na.rm= T)) %>%
group_by(Time, Color_type, Set_size) %>%
summarise(Pupil= mean(Pupil)) %>%
mutate(Set_size= as.factor(Set_size)) %>%
ggplot(aes(y= Pupil, x= Time,
color= Set_size,
linetype= Color_type,
group = interaction(Set_size, Color_type))) +
geom_line(linewidth= 1.2) +
theme(text= element_text(size= 16,
face="bold")) +
xlab("Time (s)") +
ylab("Pupil size (a.u.)") +
ggtitle("Data from: Zhou, Lorist, and Mathôt (2022)")
#the data
data= DF2
#lme4::lmer-style formula
#here we use only random intercepts
formula= "Pupil ~ Set_size*Color_type + (1|Subject)"
#you also have to supply explicitly the names of the variables
dv= "Pupil"
time= "Time"
id= "Subject"
trial= "Trial"
#how many folds?
nfolds= 3
#used for the consensus across folds - see below
t_thresh= 1.9
consensus_thresh = 0.99
cv= decode_signal(data= DF2,
formula= formula,
dv= dv,
time= time,
id= id,
trial= trial,
nfolds= nfolds,
t_thresh= t_thresh,
consensus_thresh= consensus_thresh)
cv$Peaks_test
library("pkgdown")
clean_site()
library("pkgdown")
clean_site()
build_site()
library("dplyr")
library("Pupilla")
library("ggplot2")
library("emmeans")
library("lmerTest")
library("zoo")
options(dplyr.summarise.inform = FALSE)
library("reticulate")
# #create python environment
#conda_create("my_env")
#use_miniconda("my_env")
# #install packages in the environment
# py_install("pandas")
# py_install("datamatrix")
reticulate::repl_python()
from datamatrix import io, convert
address= "data\\zhou_et_al_2021.pkl"
data= io.readpickle(address)
data= convert.to_pandas(data)
quit
setwd(choose.dir())
reticulate::repl_python()
from datamatrix import io, convert
address= "data\\zhou_et_al_2021.pkl"
data= io.readpickle(address)
data= convert.to_pandas(data)
quit
DF= py$data #bring to R
getwd()
DF2= readRDS("data/zhou et al 2022.RData")
sum(is.na(DF2$Pupil))
DF2= DF2 %>%
group_by(Subject, Trial) %>%
mutate(Pupil= zoo::na.approx(Pupil, na.rm = F))
sum(is.na(DF2$Pupil))
DF2 %>%
group_by(Subject, Time, Color_type, Set_size) %>%
summarise(Pupil= mean(Pupil, na.rm= T)) %>%
group_by(Time, Color_type, Set_size) %>%
summarise(Pupil= mean(Pupil)) %>%
mutate(Set_size= as.factor(Set_size)) %>%
ggplot(aes(y= Pupil, x= Time,
color= Set_size,
linetype= Color_type,
group = interaction(Set_size, Color_type))) +
geom_line(linewidth= 1.2) +
theme(text= element_text(size= 16,
face="bold")) +
xlab("Time (s)") +
ylab("Pupil size (a.u.)") +
ggtitle("Data from: Zhou, Lorist, and Mathôt (2022)")
#the data
data= DF2
#variables names should be supplied explicitly
dv= "Pupil"
time= "Time"
id= "Subject"
trial= "Trial"
#append to the reduced dataframe
add= c("Set_size", "Color_type")
#first change names for your convenience; it's easier this way
DF= data.frame(data)
DF$dv= DF[,colnames(DF)== dv]
DF$time= DF[,colnames(DF)== time]
DF$subject= DF[,colnames(DF)== id]
DF$trial= DF[,colnames(DF)== trial]
#these will be the rows
DF$interaction= interaction(DF$trial, DF$subject)
#set unique levels
order= unique(DF$time)
# empty= rep(NA, length(order))
# names(empty)= order
#
#get pupil as a vector
rsmat= lapply(levels(DF$interaction), function(x){
#extract time series
vec_pupil= DF$dv[DF$interaction== x]
if(length(vec_pupil)!= length(order))(vec_pupil= rep(NA, length(order)))
return(vec_pupil)
})
#merge in columns
rsmat2= do.call(cbind, rsmat)
if(sum(is.na(rsmat2))>0){
warning("NAs in the data will be discarded:
check the data (unequal timepoints maybe?)!")
}
#discard
ind= apply(rsmat2, 2, function(x)sum(is.na(x))==0)
orig= levels(DF$interaction)[ind]
rsmat3= rsmat2[,ind]
rs_mat= t(rsmat3)
Ncomp= NULL
scaling= FALSE
col_sd
col_means= apply(rs_mat, 2, mean)
col_sd= apply(rs_mat, 2, sd)
col_means
col_sd
PCA
PCA= prcomp(rs_mat, scale= scaling, center= scaling)
summaryPCA= summary(PCA)$importance
Ncomp95= as.numeric(which(summaryPCA[3,]>0.95)[1])
Ncomp95
#Ncomp changes accordingly
if(is.null(Ncomp)){
Ncomp= Ncomp95
}
if(Ncomp== "all"){
Ncomp= length(summaryPCA[3,])
}
if (Ncomp<1){
Ncomp= as.numeric(which(summaryPCA[3,]>Ncomp)[1])
}
if (Ncomp>length(summaryPCA[3,])){
warning("You asked for too many components!")
}
summaryPCA[,3]
summaryPCA[3,]
summaryPCA
summaryPCA[,1:3]
L=PCA$rotation[,1:Ncomp]
library("psych")
Ncomp
psych::principal(rsmat,
nfactors = Ncomp,
rotate= NULL)
rsmat
str(rsmat)
psych::principal(as.matrix(rsmat),
nfactors = Ncomp,
rotate= NULL)
psych::principal(unlist(rsmat),
nfactors = Ncomp,
rotate= NULL)
class(rsmat)
class(rsmat[[1]])
(rsmat[[1]])
psych::principal(rs_mat,
nfactors = Ncomp,
rotate= NULL)
rotate= "promax"
?psych::principal
rPCA= psych::principal(rs_mat,
nfactors = Ncomp,
rotate = rotate)
rPCA$loadings
str(rPCA$loadings)
rPCA$loadings[,1:Ncomp]
Loadings= rPCA$loadings[,1:Ncomp]
rPCA$values
rPCA$rotation
rPCA$Vaccounted
summaryRPCA= rPCA$Vaccounted
summaryRPCA
Loadings= rPCA$loadings[,1:Ncomp]
order
rownames(Loadings)= order
Scores= predict(PCA,
newdata= rs_mat)[,1:Ncomp]
dim(Scores)
dim( rPCA$values)
rPCA$values
rPCA$scores
rPCA$scores %>% dim()
Scores= rPCA$scores
Scores2= predict(rPCA,
newdata= rs_mat)[,1:Ncomp]
Scores2= predict(rPCA,rs_mat)[,1:Ncomp]
all_equal(Scores, Scores2)
all.equal(Scores, Scores2)
Scores= rPCA$scores
Scores= data.frame(Scores)
Scores$id= NA
Scores$trial= NA
for(i in 1:nrow(Scores)){
sel= orig[i]
Scores$id[i]= DF$subject[DF$interaction== sel][1]
Scores$trial[i]= DF$trial[DF$interaction== sel][1]
}
if(!is.null(add)){
for (a in add){
Scores$add= NA
for(i in 1:nrow(Scores)){
sel= orig[i]
Scores$add[i]= DF[DF$interaction== sel, a][1]
}
colnames(Scores)[colnames(Scores)=="add"]= a
}
}
res= list(rs_mat= rs_mat,
summaryPCA= summaryPCA,
summaryRPCA= summaryRPCA,
Loadings= Loadings,
Scores= Scores,
rPCA= rPCA,
scaling= list(M= col_means, SD= col_sd))
res$Loadings
plot(x= colnames(res$Loadings), y= res$Loadings[,1])
plot(res$Loadings[,1])
plot(res$Loadings[,2])
plot(res$Loadings[,3])
library(Pupilla)
devtools::load_all(".")
setwd(choose.dir())
# Chunk 1: setup
#knitr::knit_engines$set(python= reticulate::eng_python)
options(width = 999)
Sys.setenv(LANG = "en")
knitr::opts_chunk$set(
echo= T,
#fig.path = "images/",
eval= T,
fig.width = 7,
fig.height = 7
)
# Chunk 2
library("dplyr")
library("Pupilla")
library("ggplot2")
library("emmeans")
library("lmerTest")
library("zoo")
options(dplyr.summarise.inform = FALSE)
# Chunk 7
DF2= readRDS("data/zhou et al 2022.RData")
# Chunk 8
sum(is.na(DF2$Pupil))
DF2= DF2 %>%
group_by(Subject, Trial) %>%
mutate(Pupil= zoo::na.approx(Pupil, na.rm = F))
sum(is.na(DF2$Pupil))
# Chunk 9: mathot plot data
DF2 %>%
group_by(Subject, Time, Color_type, Set_size) %>%
summarise(Pupil= mean(Pupil, na.rm= T)) %>%
group_by(Time, Color_type, Set_size) %>%
summarise(Pupil= mean(Pupil)) %>%
mutate(Set_size= as.factor(Set_size)) %>%
ggplot(aes(y= Pupil, x= Time,
color= Set_size,
linetype= Color_type,
group = interaction(Set_size, Color_type))) +
geom_line(linewidth= 1.2) +
theme(text= element_text(size= 16,
face="bold")) +
xlab("Time (s)") +
ylab("Pupil size (a.u.)") +
ggtitle("Data from: Zhou, Lorist, and Mathôt (2022)")
library(Pupilla)
devtools::load_all("C:/Users/blini/Desktop/Pupilla/Pupilla")
#the data
data= DF2
#variables names should be supplied explicitly
dv= "Pupil"
time= "Time"
id= "Subject"
trial= "Trial"
scaling= F
rotate= "promax" #oblique rotation
#append to the reduced dataframe
add= c("Set_size", "Color_type")
rf = reduce_rPCA(
data = DF2,
dv = dv,
time = time,
id = id,
trial = trial,
scaling = scaling,
rotate= rotate,
add = add
)
rf2=rf
plot_loadings("RC1", rf2)
plot_loadings("RC2", rf2)
?psych::principal
library("pkgdown")
clean_site()

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/decode_signal2.R
\name{decode_signal2}
\alias{decode_signal2}
\title{Highlights and test the time-course of effects through crossvalidation}
\usage{
decode_signal2(
  data,
  formula,
  dv,
  time,
  id,
  trial,
  nfolds = 4,
  t_thresh = 2,
  consensus_thresh = 0.75
)
}
\arguments{
\item{data}{A data.frame containing all the necessary variables.}

\item{formula}{A 'lme4'-style formula, passed as a string.}

\item{dv}{A string indicating the name of the dependent variable.}

\item{time}{A string indicating the name of the time variable.}

\item{id}{A string indicating the name of the id (participant) variable.}

\item{trial}{A string indicating the name of the trial variable.}

\item{nfolds}{Number of folds to split trials in. Defaults to 4.}

\item{t_thresh}{Used to seek consensus: the minimum t-value required to push the
time-point forward.}

\item{consensus_thresh}{The minimum proportion of time-points that must be above
't_thresh' across folds in order to keep the time-point in the consensus.}
}
\value{
A list including: peaks retained for each (left-out) fold; test of the
retained, cross-validated peaks; test of the consensus time-points, if any; list
of time-points retained in the consensus for each effect.
}
\description{
Variant of 'decode_signal()', in which different IDs (i.e., participants)
end up in different folds. In other words, data is not splitted by trials, but by
individuals. All the other inferential approaches remains the same. The main difference
implies that stress here is on \emph{generalization across individuals} rather than
\emph{consistency across trials}.
First, each id is assigned to one fold in a
deterministic fashion (the first id to the first fold, then the second id to
the second fold, etc.).
Then, data are separated for each time-point, and a LMEM as specified by the 'formula'
parameter, which is passed to 'lmerTest::lmer', is performed by iteratively leaving
one fold out. This results in a table, with as many rows as effects implied
by the formula by 'nfolds', summarising which time point had a peak t-value (in absolute value)
in the trained folds. In a separate table these peak values are tested: the dependent
variable becomes, for each fold, the variable provided by 'dv' at that specific peak.
Another LMEM is then computed by using this newly created variable. One problem with
this approach is that peak values can be all over the places, depending on your data.
Also, choosing the time-points based on the maximum value in the training dataset can
occasionally decrease the precision of the estimate or give overfitting. You may use
this approach if you are confident that a specific effect only has an effect at a specific
window; effects with multiple windows - e.g., an early and late impact on pupil size - may
not be properly captured with this approach. Therefore,
in addition to this procedure, a very coarse consensus is seek by assessing,
across all folds and effects, which time points resulted in t-values above a certain
threshold; if the same time points pop out consistently across folds (e.g.,= 'consensus_thresh' \% of the times), then the time point is retained; all time-pointsretained in the consensus are collapsed (averaged), and a final LMEM is performed withthese time points. This can be interpreted more similarly to a cluster-basedpermutation test (although it is not the same).
}
